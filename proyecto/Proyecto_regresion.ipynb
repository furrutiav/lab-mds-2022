{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e96b59b",
   "metadata": {
    "cell_id": "00006-84a35c5d-0758-4cbb-b2ca-b182898b80d0",
    "deepnote_cell_height": 295.8833312988281,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "\n",
    "# Proyecto\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- Sebastian Avendaño\n",
    "- Felipe Urrutia\n",
    "\n",
    "- \\<Nombre de usuarios en Codalab\\>\n",
    "\n",
    "- \\<Nombre del Equipo en Codalab\\>\n",
    "\n",
    "### Link de repositorio de GitHub: https://github.com/furrutiav/lab-mds-2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8db88-52a2-47d9-8d4f-71e4fe81f833",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Librerías Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c27824f-57d0-4eea-ab8e-1db9ad9fde73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (8.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (from pyarrow) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "# Carga y Preparación de los datos\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install pyarrow\n",
    "\n",
    "# EDA\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975667a2",
   "metadata": {
    "cell_id": "00008-6607fdcd-a35f-4e75-9b46-da3b181c1551",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "## 2. Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc572b58",
   "metadata": {},
   "source": [
    "#### Carga y Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7863e",
   "metadata": {},
   "source": [
    "- Cargar los datos con Pandas y fusionar por `id`.\n",
    "- Eliminar columnas `'poster_path'`, `'backdrop_path'`, `'recommendations'`.\n",
    "- Filtrar ejemplos con `revenue` igual a 0.\n",
    "- Filtrar ejemplos con `release_date` y `runtime` nulos.\n",
    "- Convertir fechas de release_date a `pd.DateTime`.\n",
    "- Conservar solo los ejemplos con `status` `\"Released\"`.\n",
    "- Rellenar valores nulos categóricos y de texto con `''`.\n",
    "- Discretizar `vote_average` a los siguientes bins y guardar los resultados en la columna `label`: \n",
    "  - (0, 5]: `'Negative'`\n",
    "  - (5, 6]: `'Mixed'`\n",
    "  - (6, 7]: `'Mostly Positive'`\n",
    "  - (7, 8]: `'Positive'`\n",
    "  - (8, 10]: `'Very Positive'`\n",
    "- Eliminar la columna `vote_average` e `id`\n",
    "- Renombrar la columna `revenue` por `target`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161be2a",
   "metadata": {},
   "source": [
    "Cargar los datos con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9dd483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos: train_numerical_features.parquet y train_text_features.parquet\n",
    "train_numerical_features = pd.read_parquet('train_numerical_features.parquet').set_index(\"id\")\n",
    "train_text_features = pd.read_parquet('train_text_features.parquet').set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f1cec",
   "metadata": {},
   "source": [
    "Fusionar por id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d257939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_numerical_features, train_text_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202cca5",
   "metadata": {},
   "source": [
    "Eliminar columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ef5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe140d7",
   "metadata": {},
   "source": [
    "Eliminar columnas 'poster_path', 'backdrop_path', 'recommendations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c150a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['poster_path', 'backdrop_path', 'recommendations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fd31c",
   "metadata": {},
   "source": [
    "Filtrar ejemplos con revenue igual a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f2630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"revenue\"]>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fa989",
   "metadata": {},
   "source": [
    "Filtrar ejemplos con release_date y runtime nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26c07ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"release_date\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f473d059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"runtime\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7873aba",
   "metadata": {},
   "source": [
    "Convertir fechas de release_date a pd.DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecde65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"release_date\"] = df[\"release_date\"].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad39d9",
   "metadata": {},
   "source": [
    "Conservar solo los ejemplos con status \"Released\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f12ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"status\"] == \"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdfaf7",
   "metadata": {},
   "source": [
    "Rellenar valores nulos categóricos y de texto con ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05dd5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[train_text_features.columns.tolist()] = df[train_text_features.columns.tolist()].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fb62e",
   "metadata": {},
   "source": [
    "Discretizar vote_average a los siguientes bins y guardar los resultados en la columna label:\n",
    "\n",
    "    (0, 5]: 'Negative'\n",
    "    (5, 6]: 'Mixed'\n",
    "    (6, 7]: 'Mostly Positive'\n",
    "    (7, 8]: 'Positive'\n",
    "    (8, 10]: 'Very Positive'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b7c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = pd.cut(df['vote_average'], \n",
    "       bins=[0,5,6,7,8,10], \n",
    "       labels=[\"Negative\", \"Mixed\", \"Mostly Positive\", \"Positive\", \"Very Positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b637862",
   "metadata": {},
   "source": [
    "Eliminar la columna vote_average e id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50789594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"vote_average\")\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ea6b5",
   "metadata": {},
   "source": [
    "Renombrar la columna revenue por target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44993017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"revenue\": \"target\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1d117-d70a-4d15-a986-7cf773e55f44",
   "metadata": {},
   "source": [
    "Cargamos los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2131af-6ca6-4fcc-a43c-88bcfd1e5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_BERT = pickle.load(open(\"clusters_BERT.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb58815-ce59-4d5b-a93d-3c951dea7365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>target</th>\n",
       "      <th>runtime</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>credits</th>\n",
       "      <th>genres</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>release_date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>label</th>\n",
       "      <th>clusters_keywords</th>\n",
       "      <th>clusters_overview</th>\n",
       "      <th>clusters_tagline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fantastic Beasts: The Secrets of Dumbledore</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>400000000.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Return to the magic.</td>\n",
       "      <td>Jude Law-Eddie Redmayne-Mads Mikkelsen-Ezra Mi...</td>\n",
       "      <td>Fantasy-Adventure-Action</td>\n",
       "      <td>en</td>\n",
       "      <td>Professor Albus Dumbledore knows the powerful ...</td>\n",
       "      <td>Warner Bros. Pictures-Heyday Films</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>magic-curse-fantasy world-wizard-magical creat...</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sonic the Hedgehog 2</td>\n",
       "      <td>110000000.0</td>\n",
       "      <td>393000000.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Welcome to the next level.</td>\n",
       "      <td>James Marsden-Ben Schwartz-Tika Sumpter-Natash...</td>\n",
       "      <td>Action-Adventure-Family-Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>After settling in Green Hills Sonic is eager t...</td>\n",
       "      <td>Original Film-Blur Studio-Marza Animation Plan...</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>sequel-based on video game-hedgehog-live actio...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lost City</td>\n",
       "      <td>74000000.0</td>\n",
       "      <td>164289828.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>The adventure is real. The heroes are not.</td>\n",
       "      <td>Sandra Bullock-Channing Tatum-Daniel Radcliffe...</td>\n",
       "      <td>Action-Adventure-Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>A reclusive romance novelist was sure nothing ...</td>\n",
       "      <td>Paramount-Fortis Films-3dot Productions-Exhibi...</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>duringcreditsstinger</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morbius</td>\n",
       "      <td>75000000.0</td>\n",
       "      <td>161000000.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>A new Marvel legend arrives.</td>\n",
       "      <td>Jared Leto-Matt Smith-Adria Arjona-Jared Harri...</td>\n",
       "      <td>Action-Science Fiction-Fantasy</td>\n",
       "      <td>en</td>\n",
       "      <td>Dangerously ill with a rare blood disorder and...</td>\n",
       "      <td>Columbia Pictures-Avi Arad Productions-Matt To...</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>vampire-based on comic</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uncharted</td>\n",
       "      <td>120000000.0</td>\n",
       "      <td>400780000.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Fortune favors the bold.</td>\n",
       "      <td>Tom Holland-Mark Wahlberg-Sophia Ali-Tati Gabr...</td>\n",
       "      <td>Action-Adventure</td>\n",
       "      <td>en</td>\n",
       "      <td>A young street-smart Nathan Drake and his wise...</td>\n",
       "      <td>Columbia Pictures-Atlas Entertainment-PlayStat...</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>treasure-treasure hunt-based on video game-dlb</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>Amistad</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>44229441.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Freedom is not given. It is our right at birth...</td>\n",
       "      <td>Morgan Freeman-Nigel Hawthorne-Anthony Hopkins...</td>\n",
       "      <td>Drama-History-Mystery</td>\n",
       "      <td>en</td>\n",
       "      <td>In 1839 the slave ship Amistad set sail from C...</td>\n",
       "      <td>DreamWorks Pictures</td>\n",
       "      <td>1997-12-10</td>\n",
       "      <td>cuba-mutiny-slavery-sentence-historical figure...</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>Home Alone</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>476684675.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>A family comedy without the family.</td>\n",
       "      <td>Macaulay Culkin-Joe Pesci-Daniel Stern-John He...</td>\n",
       "      <td>Comedy-Family</td>\n",
       "      <td>en</td>\n",
       "      <td>Eight-year-old Kevin McCallister makes the mos...</td>\n",
       "      <td>Hughes Entertainment-20th Century Fox</td>\n",
       "      <td>1990-11-16</td>\n",
       "      <td>holiday-burglar-slapstick-little boy-family re...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>Ip Man: The Final Fight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3967001.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>Anthony Wong-Anita Yuen-Gillian Chung-Jordan C...</td>\n",
       "      <td>Action-Drama</td>\n",
       "      <td>cn</td>\n",
       "      <td>In postwar Hong Kong legendary Wing Chun grand...</td>\n",
       "      <td>Emperor Motion Pictures-Cinemasia-National Art...</td>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>biography</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>A Rainy Day in New York</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>23800000.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Love In Spring.</td>\n",
       "      <td>Timothée Chalamet-Elle Fanning-Selena Gomez-Ju...</td>\n",
       "      <td>Comedy-Romance</td>\n",
       "      <td>en</td>\n",
       "      <td>Two young people arrive in New York to spend a...</td>\n",
       "      <td>Gravier Productions-Perdido Productions-FilmNa...</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>new york city</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>The Internship</td>\n",
       "      <td>58000000.0</td>\n",
       "      <td>44000000.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Hiring them was a brilliant mistake.</td>\n",
       "      <td>Vince Vaughn-Owen Wilson-Rose Byrne-Aasif Mand...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>Two recently laid-off men in their 40s try to ...</td>\n",
       "      <td>TSG Entertainment-Regency Enterprises-Wild Wes...</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>mattress shop-job interview-rivalry-loss of jo...</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6451 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title       budget       target  \\\n",
       "0     Fantastic Beasts: The Secrets of Dumbledore  200000000.0  400000000.0   \n",
       "1                            Sonic the Hedgehog 2  110000000.0  393000000.0   \n",
       "2                                   The Lost City   74000000.0  164289828.0   \n",
       "3                                         Morbius   75000000.0  161000000.0   \n",
       "4                                       Uncharted  120000000.0  400780000.0   \n",
       "...                                           ...          ...          ...   \n",
       "6446                                      Amistad   36000000.0   44229441.0   \n",
       "6447                                   Home Alone   18000000.0  476684675.0   \n",
       "6448                      Ip Man: The Final Fight          0.0    3967001.0   \n",
       "6449                      A Rainy Day in New York   25000000.0   23800000.0   \n",
       "6450                               The Internship   58000000.0   44000000.0   \n",
       "\n",
       "     runtime    status                                            tagline  \\\n",
       "0      142.0  Released                               Return to the magic.   \n",
       "1      122.0  Released                         Welcome to the next level.   \n",
       "2      112.0  Released         The adventure is real. The heroes are not.   \n",
       "3      105.0  Released                       A new Marvel legend arrives.   \n",
       "4      116.0  Released                           Fortune favors the bold.   \n",
       "...      ...       ...                                                ...   \n",
       "6446   155.0  Released  Freedom is not given. It is our right at birth...   \n",
       "6447   103.0  Released                A family comedy without the family.   \n",
       "6448   100.0  Released                                                      \n",
       "6449    92.0  Released                                    Love In Spring.   \n",
       "6450   119.0  Released               Hiring them was a brilliant mistake.   \n",
       "\n",
       "                                                credits  \\\n",
       "0     Jude Law-Eddie Redmayne-Mads Mikkelsen-Ezra Mi...   \n",
       "1     James Marsden-Ben Schwartz-Tika Sumpter-Natash...   \n",
       "2     Sandra Bullock-Channing Tatum-Daniel Radcliffe...   \n",
       "3     Jared Leto-Matt Smith-Adria Arjona-Jared Harri...   \n",
       "4     Tom Holland-Mark Wahlberg-Sophia Ali-Tati Gabr...   \n",
       "...                                                 ...   \n",
       "6446  Morgan Freeman-Nigel Hawthorne-Anthony Hopkins...   \n",
       "6447  Macaulay Culkin-Joe Pesci-Daniel Stern-John He...   \n",
       "6448  Anthony Wong-Anita Yuen-Gillian Chung-Jordan C...   \n",
       "6449  Timothée Chalamet-Elle Fanning-Selena Gomez-Ju...   \n",
       "6450  Vince Vaughn-Owen Wilson-Rose Byrne-Aasif Mand...   \n",
       "\n",
       "                              genres original_language  \\\n",
       "0           Fantasy-Adventure-Action                en   \n",
       "1     Action-Adventure-Family-Comedy                en   \n",
       "2            Action-Adventure-Comedy                en   \n",
       "3     Action-Science Fiction-Fantasy                en   \n",
       "4                   Action-Adventure                en   \n",
       "...                              ...               ...   \n",
       "6446           Drama-History-Mystery                en   \n",
       "6447                   Comedy-Family                en   \n",
       "6448                    Action-Drama                cn   \n",
       "6449                  Comedy-Romance                en   \n",
       "6450                          Comedy                en   \n",
       "\n",
       "                                               overview  \\\n",
       "0     Professor Albus Dumbledore knows the powerful ...   \n",
       "1     After settling in Green Hills Sonic is eager t...   \n",
       "2     A reclusive romance novelist was sure nothing ...   \n",
       "3     Dangerously ill with a rare blood disorder and...   \n",
       "4     A young street-smart Nathan Drake and his wise...   \n",
       "...                                                 ...   \n",
       "6446  In 1839 the slave ship Amistad set sail from C...   \n",
       "6447  Eight-year-old Kevin McCallister makes the mos...   \n",
       "6448  In postwar Hong Kong legendary Wing Chun grand...   \n",
       "6449  Two young people arrive in New York to spend a...   \n",
       "6450  Two recently laid-off men in their 40s try to ...   \n",
       "\n",
       "                                   production_companies release_date  \\\n",
       "0                    Warner Bros. Pictures-Heyday Films   2022-04-06   \n",
       "1     Original Film-Blur Studio-Marza Animation Plan...   2022-03-30   \n",
       "2     Paramount-Fortis Films-3dot Productions-Exhibi...   2022-03-24   \n",
       "3     Columbia Pictures-Avi Arad Productions-Matt To...   2022-03-30   \n",
       "4     Columbia Pictures-Atlas Entertainment-PlayStat...   2022-02-10   \n",
       "...                                                 ...          ...   \n",
       "6446                                DreamWorks Pictures   1997-12-10   \n",
       "6447              Hughes Entertainment-20th Century Fox   1990-11-16   \n",
       "6448  Emperor Motion Pictures-Cinemasia-National Art...   2013-03-22   \n",
       "6449  Gravier Productions-Perdido Productions-FilmNa...   2019-07-26   \n",
       "6450  TSG Entertainment-Regency Enterprises-Wild Wes...   2013-06-07   \n",
       "\n",
       "                                               keywords            label  \\\n",
       "0     magic-curse-fantasy world-wizard-magical creat...  Mostly Positive   \n",
       "1     sequel-based on video game-hedgehog-live actio...         Positive   \n",
       "2                                  duringcreditsstinger  Mostly Positive   \n",
       "3                                vampire-based on comic  Mostly Positive   \n",
       "4        treasure-treasure hunt-based on video game-dlb         Positive   \n",
       "...                                                 ...              ...   \n",
       "6446  cuba-mutiny-slavery-sentence-historical figure...  Mostly Positive   \n",
       "6447  holiday-burglar-slapstick-little boy-family re...         Positive   \n",
       "6448                                          biography  Mostly Positive   \n",
       "6449                                      new york city  Mostly Positive   \n",
       "6450  mattress shop-job interview-rivalry-loss of jo...  Mostly Positive   \n",
       "\n",
       "     clusters_keywords clusters_overview clusters_tagline  \n",
       "0                    8                14               11  \n",
       "1                    7                14               11  \n",
       "2                   10                13               13  \n",
       "3                    7                10                4  \n",
       "4                   14                14                6  \n",
       "...                ...               ...              ...  \n",
       "6446                13                 0                9  \n",
       "6447                 9                 7               13  \n",
       "6448                 5                 1               -1  \n",
       "6449                 5                 9               13  \n",
       "6450                 9                12                2  \n",
       "\n",
       "[6451 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(clusters_BERT, how=\"left\", on=\"title\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa072c",
   "metadata": {
    "cell_id": "00011-95957584-71f1-4669-a6e5-9b8ac7b8d4e0",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Preprocesamiento, Holdout y Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e450ed7",
   "metadata": {},
   "source": [
    "#### ColumnTransformer y Holdout\n",
    "\n",
    "*Esta sección consiste en generar los distintos pasos para preparar sus datos con el fin de luego poder crear su modelo.*\n",
    "\n",
    "Generar un ColumnTransformer que:\n",
    "\n",
    "- Preprocese datos categóricos y ordinales.\n",
    "- Escale/estandarice datos numéricos.\n",
    "- Codifique texto.\n",
    "\n",
    "Luego, pruebe las transformaciones utilizando `fit_transform` y `get_feature_names out`.\n",
    "\n",
    "Posteriormente, ejecute un Holdout que le permita más adelante evaluar los modelos. **Recuerde eliminar los target y las labels del dataset antes de dividirlo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a208e17c",
   "metadata": {
    "cell_id": "00012-f977f172-2409-44c1-9ff4-118d043985cc",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166470,
    "source_hash": "2dc8e0f4"
   },
   "outputs": [],
   "source": [
    "## Código Holdout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b38b7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf, y_clf = df.drop(columns=[\"target\", \"label\"]), df[\"label\"]\n",
    "X_reg, y_reg = df.drop(columns=[\"target\", \"label\"]), df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91249544",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(X_clf, y_clf, test_size=0.20, random_state=23)\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.20, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14ba6691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sebastian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sebastian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98720dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9024bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Código ColumnTransformer\n",
    "atributos_minmax = [\n",
    "    \"budget\",\n",
    "    \"release_date_month\",\n",
    "    \"release_date_day\",\n",
    "    \"num_top_production_companies\",\n",
    "    \"num_top_artists\",\n",
    "    \"ratio(runtime, budget)\",\n",
    "    \"num_artists\",\n",
    "    \"num_genres\",\n",
    "    \"num_production_companies\",\n",
    "    \"prop(num_top_production_companies)\",\n",
    "    \"prop(num_top_artists)\"\n",
    "]\n",
    "atributos_st = [\n",
    "    \"runtime\",\n",
    "    \"release_date_timestamp\",\n",
    "]\n",
    "\n",
    "atributos_onehot = [\n",
    "    \"original_language\",\n",
    "    \"clusters_keywords\",\n",
    "    \"clusters_overview\",\n",
    "    \"clusters_tagline\"\n",
    "]\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc.lower())\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "    \n",
    "class SplitTokenizer:\n",
    "    def __init__(self, char=\"-\", col=\"\"):\n",
    "        self.char = char\n",
    "        self.col = col\n",
    "    def __call__(self, doc):\n",
    "        if self.col == \"production_companies\":\n",
    "            return doc.replace(\" \", \"_\").replace(\"Metro-Goldwyn-Mayer\", \"MGM\").split(self.char)\n",
    "        elif self.col == \"credits\":\n",
    "            tokens = doc.split(\"-\")\n",
    "            real_tokens = []\n",
    "            for i, tk in enumerate(tokens[:-1]):\n",
    "                if len(tokens[i+1].split()) == 1: tk = f\"{tk} {tokens[i+1]}\"\n",
    "                if len(tk.split())>1: real_tokens.append(tk)\n",
    "            return real_tokens\n",
    "        else:\n",
    "            return doc.replace(\" \", \"_\").split(self.char)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    (\"OneHot\", \n",
    "     OneHotEncoder(handle_unknown=\"ignore\"), \n",
    "     atributos_onehot\n",
    "    ),\n",
    "    (\"MinMax\", \n",
    "     MinMaxScaler(), \n",
    "     atributos_minmax\n",
    "    ),\n",
    "    (\"Standard\", \n",
    "     StandardScaler(), \n",
    "     atributos_st\n",
    "    ),\n",
    "    (\"BOW1\", \n",
    "     CountVectorizer(tokenizer= StemmerTokenizer()), \n",
    "     \"overview\"\n",
    "    ),\n",
    "    (\"OneHot_split_genres\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"genres\"\n",
    "    ),\n",
    "    (\"BOW2\", \n",
    "     CountVectorizer(tokenizer= StemmerTokenizer()), \n",
    "     \"tagline\"\n",
    "    ),\n",
    "    (\"OneHot_split_credits\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"credits\")), \n",
    "     \"credits\"\n",
    "    ),\n",
    "    (\"OneHot_split_production_companies\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"production_companies\")), \n",
    "     \"production_companies\"\n",
    "    ),\n",
    "    (\"OneHot_split_keywords\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"keywords\"\n",
    "    ),\n",
    "])\n",
    "\n",
    "ct_wo_bow = ColumnTransformer([\n",
    "    (\"OneHot\", \n",
    "     OneHotEncoder(handle_unknown=\"ignore\"), \n",
    "     atributos_onehot\n",
    "    ),\n",
    "    (\"MinMax\", \n",
    "     MinMaxScaler(), \n",
    "     atributos_minmax\n",
    "    ),\n",
    "    (\"Standard\", \n",
    "     StandardScaler(), \n",
    "     atributos_st\n",
    "    ),\n",
    "    (\"OneHot_split_genres\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"genres\"\n",
    "    ),\n",
    "    (\"OneHot_split_credits\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"credits\")), \n",
    "     \"credits\"\n",
    "    ),\n",
    "    (\"OneHot_split_production_companies\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"production_companies\")), \n",
    "     \"production_companies\"\n",
    "    ),\n",
    "    (\"OneHot_split_keywords\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"keywords\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4fa7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "Adicionalmente puede generar una nueva transformación que genere nuevas features y que se aplique antes del ColumnTransformer dentro del pipeline de los modelos. Investigar [`FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) para ver como implementar una transformación a partir de una función que tome un dataframe y entregue uno distinto en la salida.\n",
    "\n",
    "- Encodear ciclicamente los meses/días de las fechas de lanzamiento.\n",
    "- Contar cuantas veces aparecen en las peliculas ciertos personajes célebres.\n",
    "- Indicar si la pelicula es de una productora famosa o no.\n",
    "- Agrupar distintas keywords en categorías más generales.\n",
    "- Generar ratios con las variables numericas del dataset (como duración de la película/presupuesto).\n",
    "- Contar los diferentes generos similares que posee una pelicula.\n",
    "- Extraer vectores desde los overviews de las peliculas.\n",
    "- Contar el número de actores/productoras/géneros.\n",
    "- Etc... Usen su creatividad!\n",
    "\n",
    "Nuevamente, recuerde no utilizar ni los targets ni las labels para generar nuevas features.\n",
    "\n",
    "Nota: Este último paso no es requisito pero puede catapultarlos a la cima del tablero de las competencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6cd3f6",
   "metadata": {
    "cell_id": "00016-5586ef61-95ea-4f5a-8ad0-796be8c78ac0",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166471,
    "source_hash": "2dc8e0f4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbcb96b3-50ea-48d7-b0f9-1742285bda9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer(func=<function feature_extractor at 0x0000017FA68644C0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_extractor(X):\n",
    "    movies = X.copy()\n",
    "    movies[\"release_date_timestamp\"] = movies['release_date'].apply(lambda x: x.timestamp())\n",
    "    movies[\"release_date_month\"] = movies['release_date'].dt.month\n",
    "    movies[\"release_date_day\"] = movies['release_date'].dt.day\n",
    "    \n",
    "    top_companies = ['Warner Bros. Pictures', 'Universal Pictures', 'Columbia Pictures',\n",
    "       'Paramount', '20th Century Fox', 'Canal+', 'New Line Cinema',\n",
    "       'Metro-Goldwyn-Mayer', 'Lionsgate', 'Relativity Media',\n",
    "       'StudioCanal', 'Touchstone Pictures', 'Walt Disney Pictures',\n",
    "       'DreamWorks Pictures', 'Miramax']\n",
    "    \n",
    "    movies[\"num_top_production_companies\"] = movies[\"production_companies\"].apply(\n",
    "        lambda x: \n",
    "        sum(\n",
    "            [int(comp in str(x)) for comp in top_companies]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    top_artists = ['Samuel L. Jackson', 'Frank Welker', 'Nicolas Cage',\n",
    "       'Bruce Willis', 'Robert De Niro', 'Matt Damon', 'Liam Neeson',\n",
    "       'Willem Dafoe', 'Morgan Freeman', 'J.K. Simmons', 'Steve Buscemi',\n",
    "       'Johnny Depp', 'John Goodman', 'Paul Giamatti', 'Stanley Tucci',\n",
    "       'Woody Harrelson', 'Brad Pitt', 'Mickie McGowan', 'John Leguizamo',\n",
    "       'Robin Williams', 'Sylvester Stallone', 'Tom Hanks',\n",
    "       'Michael Papajohn', 'Nicole Kidman', 'Thomas Rosales Jr.',\n",
    "       'James Franco', 'Harrison Ford', 'Ben Affleck', 'Owen Wilson',\n",
    "       'Stephen Root', 'Julianne Moore', 'Ben Kingsley',\n",
    "       'Antonio Banderas', 'Anthony Hopkins', 'Alec Baldwin',\n",
    "       'Joe Chrest', 'Bill Hader', 'Richard Jenkins', 'John C. Reilly',\n",
    "       'Bill Murray', 'John Hurt', 'Elizabeth Banks', 'Michael Caine',\n",
    "       'Ewan McGregor', 'Keith David', 'Susan Sarandon',\n",
    "       'Fred Tatasciore', 'Bob Bergen', 'Scarlett Johansson',\n",
    "       'Keanu Reeves']\n",
    "    movies[\"num_top_artists\"] = movies[\"credits\"].apply(\n",
    "        lambda x: \n",
    "        sum(\n",
    "            [int(art in str(x).replace(\"-\", \" \")) for art in top_artists]\n",
    "        )\n",
    "    )\n",
    "    movies[\"ratio(runtime, budget)\"] = (movies[\"runtime\"]/(1+movies[\"budget\"]))\n",
    "    # Contar el número de actores/productoras/géneros.\n",
    "    movies[\"num_artists\"] = movies[\"credits\"].apply(\n",
    "        lambda x:\n",
    "        sum(\n",
    "            [len(str(x).split(\"-\"))]\n",
    "        )\n",
    "    )\n",
    "    movies[\"num_genres\"] = movies[\"genres\"].apply(\n",
    "        lambda x: len(str(x).split(\"-\"))\n",
    "    )\n",
    "    movies[\"num_production_companies\"] = movies[\"production_companies\"].apply(\n",
    "        lambda x: len(str(x).split(\"-\"))\n",
    "    )\n",
    "    movies[\"prop(num_top_production_companies)\"] = movies[\"num_top_production_companies\"]/(1+movies[\"num_production_companies\"])\n",
    "    movies[\"prop(num_top_artists)\"] = movies[\"num_top_artists\"]/(1+movies[\"num_artists\"])\n",
    "    return movies\n",
    "\n",
    "feature_tranformer = FunctionTransformer(feature_extractor)\n",
    "feature_tranformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89427e68",
   "metadata": {
    "cell_id": "ec9c0f8a2b044f858858ef3c3248c239",
    "deepnote_cell_height": 102,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "source": [
    "```\n",
    "Comentarios\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0f8b6",
   "metadata": {
    "cell_id": "2d58aececbe34d6184477c8e3cfaa2e3",
    "deepnote_cell_height": 117.69999694824219,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Regresión\n",
    "\n",
    "### 4.1 Dummy y Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90b527f8",
   "metadata": {
    "cell_id": "86fd465c690a46d1bafed3115c0bceff",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "234d3fe3-bda7-4305-b9d8-212341430689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Código Dummy\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "y_pred_dummy = dummy_reg.predict(X_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "feacfd42-0a43-48d1-b528-34efc86c3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f15c176",
   "metadata": {
    "cell_id": "faaf5b0b0d34479bad168c8dd4cbe508",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Código Regresor Baseline LASSO\n",
    "pipe_reg_baseline = Pipeline(\n",
    "    steps=[\n",
    "        (\"FunctionTransformer\", feature_tranformer),\n",
    "        (\"ColumnTransformer\", ct),\n",
    "        (\"reg\", linear_model.Lasso(alpha=0.1))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed694e87-8791-4c0e-9428-15ee9ac8268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.8 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('FunctionTransformer',\n",
       "                 FunctionTransformer(func=<function feature_extractor at 0x0000017FA68644C0>)),\n",
       "                ('ColumnTransformer',\n",
       "                 ColumnTransformer(transformers=[('OneHot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['original_language',\n",
       "                                                   'clusters_keywords',\n",
       "                                                   'clusters_overview',\n",
       "                                                   'clusters_tagline']),\n",
       "                                                 ('MinMax', MinMaxScaler(),\n",
       "                                                  ['budget',\n",
       "                                                   'release_date_mon...\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017FA68694F0>),\n",
       "                                                  'credits'),\n",
       "                                                 ('OneHot_split_production_companies',\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017FA6869670>),\n",
       "                                                  'production_companies'),\n",
       "                                                 ('OneHot_split_keywords',\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017FA6869550>),\n",
       "                                                  'keywords')])),\n",
       "                ('reg', Lasso(alpha=0.1))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe_reg_baseline.fit(X_reg_train, y_reg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a49fab5-5dc5-4937-ab65-aad8e6ebdca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.23 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_reg_baseline = pipe_reg_baseline.predict(X_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8913518-e529-411e-b6c6-7a8277d35e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2627b4",
   "metadata": {
    "cell_id": "4e397759bca54254b536d998f20cbd08",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresor Dummy\n",
      "-0.0003707986340903968\n"
     ]
    }
   ],
   "source": [
    "## Código Comparación de métricas\n",
    "print(\n",
    "    \"Regresor Dummy\\n\"+str(r2_score(y_reg_test, y_pred_dummy))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de91e419-e970-488b-8a03-da23566c0c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresor baseline: Lasso\n",
      "0.11560134261108834\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Regresor baseline: Lasso\\n\"+str(r2_score(y_reg_test, y_reg_baseline))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d457dd",
   "metadata": {
    "cell_id": "23ba7e6c56c841d8b2c11563ca64bf20",
    "deepnote_cell_height": 69.93333435058594,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "```\n",
    "Justificación\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb1c44",
   "metadata": {
    "cell_id": "df491c3ed9704211be52235df236b889",
    "deepnote_cell_height": 61.69999694824219,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 4.2 Búsqueda del mejor modelo de Regresión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7742c219-31fc-46e7-89cc-30291dbb32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30d3b694-5c97-472a-a56e-ec11e0567b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipe_reg(model_class, params, params_selector):\n",
    "    model = model_class(**params)\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"FunctionTransformer\", feature_tranformer),\n",
    "            (\"ColumnTransformer\", ct),\n",
    "            (\"selector\", SelectPercentile(f_classif, **params_selector)),\n",
    "            ('reg', model)\n",
    "        ]\n",
    "     )\n",
    "    pipe.fit(X_reg_train, y_reg_train)\n",
    "    y_pred = pipe.predict(X_reg_test)\n",
    "    print(\n",
    "    f\"Clasificador: {model_class.__name__}\\n\"+str(r2_score(y_reg_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36e5c1aa-03c0-4b1a-b26b-1a9d55c3d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: Ridge\n",
      "0.5369578278507092\n",
      "CPU times: total: 26.4 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_reg(\n",
    "    linear_model.Ridge,\n",
    "    params={\n",
    "        \"alpha\":2,\n",
    "        'tol':1e-5\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9a66111-8765-4422-8837-cfc75d38163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: ElasticNet\n",
      "0.3247377660809302\n",
      "CPU times: total: 57 s\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#en gridsearch usar este en vez de los dos anteriores, e incluir l1_ratio=1 para Lasso\n",
    "test_pipe_reg( \n",
    "    linear_model.ElasticNet,\n",
    "    params={\n",
    "        \"alpha\":0.5,\n",
    "        'tol':1e-4,\n",
    "        'l1_ratio':0.5\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7415036-4f1d-4cf7-8cda-364cdc3cf4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: BaggingRegressor\n",
      "0.5338382663146124\n",
      "CPU times: total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_reg( \n",
    "    BaggingRegressor,\n",
    "    params={\n",
    "        'base_estimator': DecisionTreeRegressor(),\n",
    "        'n_estimators': 10,\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3dc63a29-bafb-4b98-ae64-f831a89d8774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: GradientBoostingRegressor\n",
      "0.5769260305671147\n",
      "CPU times: total: 35 s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_reg( \n",
    "    GradientBoostingRegressor,\n",
    "    params={\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a5c5c-a8d1-4bce-886c-3c91694bd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_pipe_reg( \n",
    "    RandomForestRegressor,\n",
    "    params={\n",
    "        'max_depth': None\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51453725-b27b-4e50-a933-14c212d35823",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"FunctionTransformer\", feature_tranformer),\n",
    "            (\"ColumnTransformer\", ct),\n",
    "            (\"selector\", SelectPercentile(f_classif, percentile=50)),\n",
    "            (\"reg\", linear_model.Lasso(alpha=0.1))\n",
    "        ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2e3823b8",
   "metadata": {
    "cell_id": "cfc6786c0598444bb8070990453da397",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código GridSearch\n",
    "param_grid = [\n",
    "    # grilla 1: Ridge\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"reg\": [linear_model.Ridge(random_state=42)],\n",
    "        \"reg__alpha\": [0.5, 1, 2],\n",
    "        \"reg__tol\": [1e-3, 1e-4, 1e-5],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 2: ElasticNet\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"reg\": [linear_model.ElasticNet(random_state=42)],\n",
    "        \"reg__alpha\": [0.5, 1, 2],\n",
    "        \"reg__l1_ratio\": [0.5, 0.75, 1],\n",
    "        \"reg__tol\": [1e-3, 1e-4, 1e-5],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 3: Bagging\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"reg\": [BaggingRegressor(base_estimator=DecisionTreeRegressor(), random_state=42)],\n",
    "        \"reg__n_estimators\": [5, 10, 20],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 4: GradientBoosting\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"reg\": [GradientBoostingRegressor(random_state=42)],\n",
    "        \"reg__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"reg__n_estimators\": [50, 100, 200],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 5: RandomForest\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"reg\": [RandomForestRegressor(random_state=42)],\n",
    "        \"reg__n_estimators\": [50, 100, 200],\n",
    "        \"reg__max_depth\": [2, 5, 10],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed23a3c4-a343-4fd6-bfac-1fc53cede928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "75ceb994-670e-4c97-94b9-c71b9c9cb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgs = HalvingGridSearchCV(pipe, param_grid, n_jobs=-1, scoring='r2', verbose=10, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "95efa281-fa20-476e-81f7-79f57a9a068d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 6\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 21\n",
      "max_resources_: 5160\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 570\n",
      "n_resources: 21\n",
      "Fitting 5 folds for each of 570 candidates, totalling 2850 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 190\n",
      "n_resources: 63\n",
      "Fitting 5 folds for each of 190 candidates, totalling 950 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 64\n",
      "n_resources: 189\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(151, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 327, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(151, 0)) while a minimum of 1 is required.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [137]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_reg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_reg_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:262\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_parameters(\n\u001b[0;32m    255\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    256\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    257\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples_orig \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y\u001b[38;5;241m=\u001b[39my, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_index_]\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:367\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    360\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checked_cv_orig\n\u001b[0;32m    362\u001b[0m more_results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m\"\u001b[39m: [itr] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: [n_resources] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[0;32m    365\u001b[0m }\n\u001b[1;32m--> 367\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmore_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmore_results\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m n_candidates_to_keep \u001b[38;5;241m=\u001b[39m ceil(n_candidates \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor)\n\u001b[0;32m    372\u001b[0m candidate_params \u001b[38;5;241m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(151, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "hgs.fit(X_reg_train, y_reg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a1a1589b-4428-4ed1-b3ae-fe00fd6ccc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8c0c805a-726b-4229-9e68-4161bb5c34a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('FunctionTransformer',\n",
       "   FunctionTransformer(func=<function feature_extractor at 0x0000017FA68644C0>)),\n",
       "  ('ColumnTransformer',\n",
       "   ColumnTransformer(transformers=[('OneHot',\n",
       "                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                    ['original_language', 'clusters_keywords',\n",
       "                                     'clusters_overview', 'clusters_tagline']),\n",
       "                                   ('MinMax', MinMaxScaler(),\n",
       "                                    ['budget', 'release_date_month',\n",
       "                                     'release_date_day',\n",
       "                                     'num_top_production_companies',\n",
       "                                     'num_top_artists', 'ratio(runtime, budget)',\n",
       "                                     'num_artists', 'num_genres',\n",
       "                                     'num_product...\n",
       "                                   ('OneHot_split_credits',\n",
       "                                    CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017FA914A280>),\n",
       "                                    'credits'),\n",
       "                                   ('OneHot_split_production_companies',\n",
       "                                    CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFB160>),\n",
       "                                    'production_companies'),\n",
       "                                   ('OneHot_split_keywords',\n",
       "                                    CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFBA30>),\n",
       "                                    'keywords')])),\n",
       "  ('selector', SelectPercentile(percentile=95)),\n",
       "  ('reg', Ridge(alpha=1, random_state=42, tol=0.0001))],\n",
       " 'verbose': False,\n",
       " 'FunctionTransformer': FunctionTransformer(func=<function feature_extractor at 0x0000017FA68644C0>),\n",
       " 'ColumnTransformer': ColumnTransformer(transformers=[('OneHot',\n",
       "                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                  ['original_language', 'clusters_keywords',\n",
       "                                   'clusters_overview', 'clusters_tagline']),\n",
       "                                 ('MinMax', MinMaxScaler(),\n",
       "                                  ['budget', 'release_date_month',\n",
       "                                   'release_date_day',\n",
       "                                   'num_top_production_companies',\n",
       "                                   'num_top_artists', 'ratio(runtime, budget)',\n",
       "                                   'num_artists', 'num_genres',\n",
       "                                   'num_product...\n",
       "                                 ('OneHot_split_credits',\n",
       "                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017FA914A280>),\n",
       "                                  'credits'),\n",
       "                                 ('OneHot_split_production_companies',\n",
       "                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFB160>),\n",
       "                                  'production_companies'),\n",
       "                                 ('OneHot_split_keywords',\n",
       "                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFBA30>),\n",
       "                                  'keywords')]),\n",
       " 'selector': SelectPercentile(percentile=95),\n",
       " 'reg': Ridge(alpha=1, random_state=42, tol=0.0001),\n",
       " 'FunctionTransformer__accept_sparse': False,\n",
       " 'FunctionTransformer__check_inverse': True,\n",
       " 'FunctionTransformer__func': <function __main__.feature_extractor(X)>,\n",
       " 'FunctionTransformer__inv_kw_args': None,\n",
       " 'FunctionTransformer__inverse_func': None,\n",
       " 'FunctionTransformer__kw_args': None,\n",
       " 'FunctionTransformer__validate': False,\n",
       " 'ColumnTransformer__n_jobs': None,\n",
       " 'ColumnTransformer__remainder': 'drop',\n",
       " 'ColumnTransformer__sparse_threshold': 0.3,\n",
       " 'ColumnTransformer__transformer_weights': None,\n",
       " 'ColumnTransformer__transformers': [('OneHot',\n",
       "   OneHotEncoder(handle_unknown='ignore'),\n",
       "   ['original_language',\n",
       "    'clusters_keywords',\n",
       "    'clusters_overview',\n",
       "    'clusters_tagline']),\n",
       "  ('MinMax',\n",
       "   MinMaxScaler(),\n",
       "   ['budget',\n",
       "    'release_date_month',\n",
       "    'release_date_day',\n",
       "    'num_top_production_companies',\n",
       "    'num_top_artists',\n",
       "    'ratio(runtime, budget)',\n",
       "    'num_artists',\n",
       "    'num_genres',\n",
       "    'num_production_companies',\n",
       "    'prop(num_top_production_companies)',\n",
       "    'prop(num_top_artists)']),\n",
       "  ('Standard', StandardScaler(), ['runtime', 'release_date_timestamp']),\n",
       "  ('OneHot_split_genres',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F8AC6DBE0>),\n",
       "   'genres'),\n",
       "  ('OneHot_split_credits',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017FA914A280>),\n",
       "   'credits'),\n",
       "  ('OneHot_split_production_companies',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFB160>),\n",
       "   'production_companies'),\n",
       "  ('OneHot_split_keywords',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFBA30>),\n",
       "   'keywords')],\n",
       " 'ColumnTransformer__verbose': False,\n",
       " 'ColumnTransformer__verbose_feature_names_out': True,\n",
       " 'ColumnTransformer__OneHot': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'ColumnTransformer__MinMax': MinMaxScaler(),\n",
       " 'ColumnTransformer__Standard': StandardScaler(),\n",
       " 'ColumnTransformer__OneHot_split_genres': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F8AC6DBE0>),\n",
       " 'ColumnTransformer__OneHot_split_credits': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017FA914A280>),\n",
       " 'ColumnTransformer__OneHot_split_production_companies': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFB160>),\n",
       " 'ColumnTransformer__OneHot_split_keywords': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000017F82FFBA30>),\n",
       " 'ColumnTransformer__OneHot__categories': 'auto',\n",
       " 'ColumnTransformer__OneHot__drop': None,\n",
       " 'ColumnTransformer__OneHot__dtype': numpy.float64,\n",
       " 'ColumnTransformer__OneHot__handle_unknown': 'ignore',\n",
       " 'ColumnTransformer__OneHot__sparse': True,\n",
       " 'ColumnTransformer__MinMax__clip': False,\n",
       " 'ColumnTransformer__MinMax__copy': True,\n",
       " 'ColumnTransformer__MinMax__feature_range': (0, 1),\n",
       " 'ColumnTransformer__Standard__copy': True,\n",
       " 'ColumnTransformer__Standard__with_mean': True,\n",
       " 'ColumnTransformer__Standard__with_std': True,\n",
       " 'ColumnTransformer__OneHot_split_genres__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_genres__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_genres__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_genres__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_genres__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_genres__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_genres__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_genres__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_genres__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_genres__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_genres__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_genres__tokenizer': <__main__.SplitTokenizer at 0x17f8ac6dbe0>,\n",
       " 'ColumnTransformer__OneHot_split_genres__vocabulary': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_credits__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_credits__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_credits__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_credits__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_credits__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_credits__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_credits__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_credits__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_credits__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_credits__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_credits__tokenizer': <__main__.SplitTokenizer at 0x17fa914a280>,\n",
       " 'ColumnTransformer__OneHot_split_credits__vocabulary': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_production_companies__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__tokenizer': <__main__.SplitTokenizer at 0x17f82ffb160>,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__vocabulary': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_keywords__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_keywords__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_keywords__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_keywords__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_keywords__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_keywords__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_keywords__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_keywords__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_keywords__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_keywords__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_keywords__tokenizer': <__main__.SplitTokenizer at 0x17f82ffba30>,\n",
       " 'ColumnTransformer__OneHot_split_keywords__vocabulary': None,\n",
       " 'selector__percentile': 95,\n",
       " 'selector__score_func': <function sklearn.feature_selection._univariate_selection.f_classif(X, y)>,\n",
       " 'reg__alpha': 1,\n",
       " 'reg__copy_X': True,\n",
       " 'reg__fit_intercept': True,\n",
       " 'reg__max_iter': None,\n",
       " 'reg__normalize': 'deprecated',\n",
       " 'reg__positive': False,\n",
       " 'reg__random_state': 42,\n",
       " 'reg__solver': 'auto',\n",
       " 'reg__tol': 0.0001}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipe = hgs.best_estimator_\n",
    "best_pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165c371",
   "metadata": {
    "cell_id": "b00b9baef48947d9abcfb6972bdaa3aa",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código Predicción de datos de la competencia aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce5d7d1",
   "metadata": {
    "cell_id": "00025-2acf9c12-da85-4c1f-add5-f2b0f600177f",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Conclusiones Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996db4c2",
   "metadata": {
    "cell_id": "00026-15c07b20-0e16-48fa-bf3c-33aeb2c4c1db",
    "deepnote_cell_height": 51.53334045410156,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Conclusiones...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18bac5d",
   "metadata": {
    "cell_id": "00027-1e362e1d-a776-4423-93d5-0f568476e4c1",
    "deepnote_cell_height": 84.10000610351562,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Anexo: Generación de Archivo Submit de la Competencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f6447",
   "metadata": {
    "cell_id": "00028-0a64e7e8-1077-4868-8c96-db3d51323157",
    "deepnote_cell_height": 671.9000244140625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Para subir los resultados obtenidos a la pagina de CodaLab utilice la función `generateFiles` entregada mas abajo. Esto es debido a que usted deberá generar archivos que respeten extrictamente el formato de CodaLab, de lo contario los resultados no se veran reflejados en la pagina de la competencia.\n",
    "\n",
    "Para los resultados obtenidos en su modelo de clasificación y regresión, estos serán guardados en un archivo zip que contenga los archivos `predicctions_clf.txt` para la clasificación y `predicctions_rgr.clf` para la regresión. Los resultados, como se comento antes, deberan ser obtenidos en base al dataset `test.pickle` y en cada una de las lineas deberan presentar las predicciones realizadas.\n",
    "\n",
    "Ejemplos de archivos:\n",
    "\n",
    "- [ ] `predicctions_clf.txt`\n",
    "\n",
    "        Mostly Positive\n",
    "        Mostly Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        ...\n",
    "\n",
    "- [ ] `predicctions_rgr.txt`\n",
    "\n",
    "        16103.58\n",
    "        16103.58\n",
    "        16041.89\n",
    "        9328.62\n",
    "        107976.03\n",
    "        194374.08\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f33d5d",
   "metadata": {
    "cell_id": "00029-55f95a4c-2d1f-4354-a690-049fea34bdac",
    "deepnote_cell_height": 620.13330078125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166501,
    "source_hash": "b1cdf32f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "def generateFiles(predict_data, clf_pipe, rgr_pipe):\n",
    "    \"\"\"Genera los archivos a subir en CodaLab\n",
    "\n",
    "    Input\n",
    "    predict_data: Dataframe con los datos de entrada a predecir\n",
    "    clf_pipe: pipeline del clf\n",
    "    rgr_pipe: pipeline del rgr\n",
    "\n",
    "    Ouput\n",
    "    archivo de txt\n",
    "    \"\"\"\n",
    "    y_pred_clf = clf_pipe.predict(predict_data)\n",
    "    y_pred_rgr = rgr_pipe.predict(predict_data)\n",
    "    \n",
    "    with open('./predictions_clf.txt', 'w') as f:\n",
    "        for item in y_pred_clf:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open('./predictions_rgr.txt', 'w') as f:\n",
    "        for item in y_pred_rgr:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with ZipFile('predictions.zip', 'w') as zipObj2:\n",
    "       zipObj2.write('predictions_rgr.txt')\n",
    "       zipObj2.write('predictions_clf.txt')\n",
    "\n",
    "    os.remove(\"predictions_rgr.txt\")\n",
    "    os.remove(\"predictions_clf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1efe0",
   "metadata": {
    "cell_id": "b589f659ce2246919e3707e79420aff2",
    "deepnote_cell_height": 138,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejecutar función para generar el archivo de predicciones.\n",
    "# perdict_data debe tener cargada los datos del text.pickle\n",
    "# mientras que clf_pipe y rgr_pipe, son los pipeline de \n",
    "# clasificación y regresión respectivamente.\n",
    "generateFiles(predict_data, clf_pipe, rgr_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f8d39",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "dbddc0f3-10b8-4160-bc27-ac993196164c",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e96b59b",
   "metadata": {
    "cell_id": "00006-84a35c5d-0758-4cbb-b2ca-b182898b80d0",
    "deepnote_cell_height": 295.8833312988281,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "\n",
    "# Proyecto\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- Sebastian Avendaño\n",
    "- Felipe Urrutia\n",
    "\n",
    "- \\<Nombre de usuarios en Codalab\\>\n",
    "\n",
    "- \\<Nombre del Equipo en Codalab\\>\n",
    "\n",
    "### Link de repositorio de GitHub: https://github.com/furrutiav/lab-mds-2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8db88-52a2-47d9-8d4f-71e4fe81f833",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Librerías Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c27824f-57d0-4eea-ab8e-1db9ad9fde73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\felip\\anaconda3\\lib\\site-packages (8.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from pyarrow) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "# 1. Carga y Preparación de los datos\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 2. Preprocess\n",
    "## Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "## Preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer\n",
    "## ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "## FunctionTransfomer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# 3. Regression\n",
    "## Dummy y Baseline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "## Modelos\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## Gridsearch\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "# Prediccion\n",
    "from zipfile import ZipFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975667a2",
   "metadata": {
    "cell_id": "00008-6607fdcd-a35f-4e75-9b46-da3b181c1551",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "## 1. Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc572b58",
   "metadata": {},
   "source": [
    "#### Carga y Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7863e",
   "metadata": {},
   "source": [
    "En esta subseccion realizaremos la carga y preparacion de los datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161be2a",
   "metadata": {},
   "source": [
    "**Cargar los datos con Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9dd483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos numericos\n",
    "train_numerical_features = pd.read_parquet(\n",
    "    'train_numerical_features.parquet'\n",
    ").set_index(\"id\")\n",
    "# Atributos textuales\n",
    "train_text_features = pd.read_parquet(\n",
    "    'train_text_features.parquet'\n",
    ").set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f1cec",
   "metadata": {},
   "source": [
    "**Fusionar por id:** Fusionamos ambos conjuntos de datos sobre la llave $\\texttt{id}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d257939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_numerical_features, train_text_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202cca5",
   "metadata": {},
   "source": [
    "**Eliminar columnas duplicadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ef5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe140d7",
   "metadata": {},
   "source": [
    "**Eliminar columnas $\\texttt{poster_path}$, $\\texttt{backdrop_path}$, $\\texttt{recommendations}$:** Columnas que no son utiles para nuestro problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c150a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['poster_path', 'backdrop_path', 'recommendations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fd31c",
   "metadata": {},
   "source": [
    "**Filtrar ejemplos con valor de la variable $\\texttt{revenue}$ igual a 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f2630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"revenue\"]>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fa989",
   "metadata": {},
   "source": [
    "**Filtrar ejemplos con $\\texttt{release_date}$ y $\\texttt{runtime}$ nulos** (Nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d4af4-d734-46e9-9156-72cb587e4d08",
   "metadata": {},
   "source": [
    "$\\texttt{release_date}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26c07ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"release_date\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c9528-60aa-44c6-9595-5d33689b2914",
   "metadata": {},
   "source": [
    "$\\texttt{runtime}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f473d059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"runtime\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7873aba",
   "metadata": {},
   "source": [
    "**Convertir fechas de $\\texttt{release_date}$ a $\\texttt{pd.DateTime}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecde65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"release_date\"] = df[\"release_date\"].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad39d9",
   "metadata": {},
   "source": [
    "**Conservar solo los ejemplos con valor de $\\texttt{status}$ igual a $\\texttt{Released}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f12ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"status\"] == \"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdfaf7",
   "metadata": {},
   "source": [
    "**Rellenar valores nulos categóricos y de texto con ' '**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05dd5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[train_text_features.columns.tolist()] = df[train_text_features.columns.tolist()].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fb62e",
   "metadata": {},
   "source": [
    "**Discretizar vote_average a los siguientes bins y guardar los resultados en la columna label:**\n",
    "\n",
    "    (0, 5]: 'Negative'\n",
    "    (5, 6]: 'Mixed'\n",
    "    (6, 7]: 'Mostly Positive'\n",
    "    (7, 8]: 'Positive'\n",
    "    (8, 10]: 'Very Positive'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b7c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = pd.cut(df['vote_average'], \n",
    "       bins=[0,5,6,7,8,10], \n",
    "       labels=[\"Negative\", \"Mixed\", \"Mostly Positive\", \"Positive\", \"Very Positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b637862",
   "metadata": {},
   "source": [
    "**Eliminar la columna $\\texttt{vote_average}$ e $\\texttt{id}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50789594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"vote_average\")\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ea6b5",
   "metadata": {},
   "source": [
    "**Renombrar la columna $\\texttt{revenue}$ por $\\texttt{target}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44993017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"revenue\": \"target\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b033bfe6-7bf7-45ae-96d1-976df90b6a57",
   "metadata": {},
   "source": [
    "**Cargamos los clusters obtenidos con KMeans y BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1d117-d70a-4d15-a986-7cf773e55f44",
   "metadata": {},
   "source": [
    "Estos datos son un conjunto de las siguientes tres variables:\n",
    "* $\\texttt{clusters_keywords}$\n",
    "* $\\texttt{clusters_overview}$\n",
    "* $\\texttt{clusters_tagline}$\n",
    "\n",
    "Cada una identifica el cluster al que pertenece la pelicula cuando se obtiene el sentence embedding usando BERT del texto de $\\texttt{keywords}$, $\\texttt{overview}$ y $\\texttt{tagline}$, según corresponda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2131af-6ca6-4fcc-a43c-88bcfd1e5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_BERT = pickle.load(open(\"clusters_BERT.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31c34d-c585-4579-83bb-bead53000ceb",
   "metadata": {},
   "source": [
    "Unimos estas nuevas variables con el dataframe principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb58815-ce59-4d5b-a93d-3c951dea7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(clusters_BERT, how=\"left\", on=\"title\")\n",
    "df[\"clusters_keywords clusters_overview clusters_tagline\".split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa072c",
   "metadata": {
    "cell_id": "00011-95957584-71f1-4669-a6e5-9b8ac7b8d4e0",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. Preprocesamiento, Holdout y Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36e6c2-630d-4461-b902-02bceefada76",
   "metadata": {},
   "source": [
    "#### ColumnTransformer y Holdout\n",
    "\n",
    "<!-- *Esta sección consiste en generar los distintos pasos para preparar sus datos con el fin de luego poder crear su modelo.*\n",
    "\n",
    "Generar un ColumnTransformer que:\n",
    "\n",
    "- Preprocese datos categóricos y ordinales.\n",
    "- Escale/estandarice datos numéricos.\n",
    "- Codifique texto.\n",
    "\n",
    "Luego, pruebe las transformaciones utilizando `fit_transform` y `get_feature_names out`.\n",
    "\n",
    "Posteriormente, ejecute un Holdout que le permita más adelante evaluar los modelos. **Recuerde eliminar los target y las labels del dataset antes de dividirlo**. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f1aeca-f8a9-4f41-b5ab-90d1a46a0a73",
   "metadata": {},
   "source": [
    "**Holdout train/test para cada problema de predicción**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e458a79-b5e2-46dc-8c19-d063cffbfc7d",
   "metadata": {},
   "source": [
    "Separamos los conjuntos de datos para cada problema, con sus respectivas variables a predecir y omitiendo en cada conjunto ambas variables a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b38b7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Código Holdout\n",
    "X_clf, y_clf = df.drop(columns=[\"target\", \"label\"]), df[\"label\"]\n",
    "X_reg, y_reg = df.drop(columns=[\"target\", \"label\"]), df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead8dc5-eba8-4366-9991-f7d23689645a",
   "metadata": {},
   "source": [
    "Split de los datos para cada problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91249544",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(X_clf, y_clf, test_size=0.20, random_state=23)\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.20, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6feae12-527b-404b-b38e-16632d38df1f",
   "metadata": {},
   "source": [
    "**ColumnTransformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780993f1-84ea-45c6-a86e-90e1fd28abad",
   "metadata": {},
   "source": [
    "Codigo de ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da8eb3-f22b-423e-93d8-16d79665419d",
   "metadata": {},
   "source": [
    "En la celda que sigue se mencionan aquellas variables numericas que pasaran por una transformación minmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa350629-c504-4ab2-b323-c595e6352717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atributos_minmax = [\n",
    "    \"budget\",\n",
    "    \"release_date_month\",\n",
    "    \"release_date_day\",\n",
    "    \"num_top_production_companies\",\n",
    "    \"num_top_artists\",\n",
    "    \"ratio(runtime, budget)\",\n",
    "    \"num_artists\",\n",
    "    \"num_genres\",\n",
    "    \"num_production_companies\",\n",
    "    \"prop(num_top_production_companies)\",\n",
    "    \"prop(num_top_artists)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c50af-18a9-4d5b-880b-2a4d6666b4f1",
   "metadata": {},
   "source": [
    "En la celda que sigue se mencionan aquellas variables numericas que pasaran por una transformación *standard*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d55ecf-e27a-4fa8-a525-b4e483384b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_st = [\n",
    "    \"runtime\",\n",
    "    \"release_date_timestamp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedbc1be-d852-4220-b3c6-150f4701f3e1",
   "metadata": {},
   "source": [
    "En la celda que sigue se mencionan aquellas variables categoricas que pasaran por una vectorizacion OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916c638-7a57-4a8c-b03a-1678c6448aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_onehot = [\n",
    "    \"original_language\",\n",
    "    \"clusters_keywords\",\n",
    "    \"clusters_overview\",\n",
    "    \"clusters_tagline\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79479fd7-2898-4cbd-97dd-e12d63ad01de",
   "metadata": {},
   "source": [
    "Consideramos dos tipos de tokenizadores. El primero, *StemmerTokenizer*, para preprocesar el texto que luego sera vectorizados con bag-of-words. Y el segundo, *SplitTokenizer*, para preprocesar el texto catergorico separado por guiones para luego vectorizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffbd3959-9077-45b2-8bf9-3164962b8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc.lower())\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "    \n",
    "class SplitTokenizer:\n",
    "    def __init__(self, char=\"-\", col=\"\"):\n",
    "        self.char = char\n",
    "        self.col = col\n",
    "    def __call__(self, doc):\n",
    "        if self.col == \"production_companies\":\n",
    "            return doc.replace(\" \", \"_\").replace(\"Metro-Goldwyn-Mayer\", \"MGM\").split(self.char)\n",
    "        elif self.col == \"credits\":\n",
    "            tokens = doc.split(\"-\")\n",
    "            real_tokens = []\n",
    "            for i, tk in enumerate(tokens[:-1]):\n",
    "                if len(tokens[i+1].split()) == 1: tk = f\"{tk} {tokens[i+1]}\"\n",
    "                if len(tk.split())>1: real_tokens.append(tk)\n",
    "            return real_tokens\n",
    "        else:\n",
    "            return doc.replace(\" \", \"_\").split(self.char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c8c2d-56c1-4163-8352-67b06adc6368",
   "metadata": {},
   "source": [
    "En este trabajo estudiamos dos *ColumnTransformer*. Uno de ellos es una version sin bag-of-words del otro, denotando por *ct_wo_bow* al primero, y *ct* al segundo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac42daa-96c0-4d92-bd15-95d90b932997",
   "metadata": {},
   "source": [
    "ColumnTransformer *ct*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c962e39-b403-450a-9cd9-a99e1313af33",
   "metadata": {},
   "source": [
    "* MinMaxScaler: atributos_minmax\n",
    "* StandardScaler: atributos_st\n",
    "* BOW: overview, tagline\n",
    "* OneHot: atributos_onehot\n",
    "* OneHot(split): genres, credits, production_companies, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f643f41-ecdd-4b8f-be95-35dcb345c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([\n",
    "    (\"OneHot\", \n",
    "     OneHotEncoder(handle_unknown=\"ignore\"), \n",
    "     atributos_onehot\n",
    "    ),\n",
    "    (\"MinMax\", \n",
    "     MinMaxScaler(), \n",
    "     atributos_minmax\n",
    "    ),\n",
    "    (\"Standard\", \n",
    "     StandardScaler(), \n",
    "     atributos_st\n",
    "    ),\n",
    "    (\"BOW1\", \n",
    "     CountVectorizer(tokenizer= StemmerTokenizer()), \n",
    "     \"overview\"\n",
    "    ),\n",
    "    (\"OneHot_split_genres\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"genres\"\n",
    "    ),\n",
    "    (\"BOW2\", \n",
    "     CountVectorizer(tokenizer= StemmerTokenizer()), \n",
    "     \"tagline\"\n",
    "    ),\n",
    "    (\"OneHot_split_credits\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"credits\")), \n",
    "     \"credits\"\n",
    "    ),\n",
    "    (\"OneHot_split_production_companies\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"production_companies\")), \n",
    "     \"production_companies\"\n",
    "    ),\n",
    "    (\"OneHot_split_keywords\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"keywords\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8043c-74c4-4512-8adf-a6a8d38be60f",
   "metadata": {},
   "source": [
    "ColumnTransformer *ct_wo_bow*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c45d33-20df-490a-a0c6-bc401ee044a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_wo_bow = ColumnTransformer([\n",
    "    (\"OneHot\", \n",
    "     OneHotEncoder(handle_unknown=\"ignore\"), \n",
    "     atributos_onehot\n",
    "    ),\n",
    "    (\"MinMax\", \n",
    "     MinMaxScaler(), \n",
    "     atributos_minmax\n",
    "    ),\n",
    "    (\"Standard\", \n",
    "     StandardScaler(), \n",
    "     atributos_st\n",
    "    ),\n",
    "    (\"OneHot_split_genres\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"genres\"\n",
    "    ),\n",
    "    (\"OneHot_split_credits\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"credits\")), \n",
    "     \"credits\"\n",
    "    ),\n",
    "    (\"OneHot_split_production_companies\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"production_companies\")), \n",
    "     \"production_companies\"\n",
    "    ),\n",
    "    (\"OneHot_split_keywords\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"keywords\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfcb79-5c6d-4eca-b71f-bc3166232788",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "<!-- Adicionalmente puede generar una nueva transformación que genere nuevas features y que se aplique antes del ColumnTransformer dentro del pipeline de los modelos. Investigar [`FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) para ver como implementar una transformación a partir de una función que tome un dataframe y entregue uno distinto en la salida.\n",
    "\n",
    "- Encodear ciclicamente los meses/días de las fechas de lanzamiento.\n",
    "- Contar cuantas veces aparecen en las peliculas ciertos personajes célebres.\n",
    "- Indicar si la pelicula es de una productora famosa o no.\n",
    "- Agrupar distintas keywords en categorías más generales.\n",
    "- Generar ratios con las variables numericas del dataset (como duración de la película/presupuesto).\n",
    "- Contar los diferentes generos similares que posee una pelicula.\n",
    "- Extraer vectores desde los overviews de las peliculas.\n",
    "- Contar el número de actores/productoras/géneros.\n",
    "- Etc... Usen su creatividad!\n",
    "\n",
    "Nuevamente, recuerde no utilizar ni los targets ni las labels para generar nuevas features.\n",
    "\n",
    "Nota: Este último paso no es requisito pero puede catapultarlos a la cima del tablero de las competencias. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7525747-ef72-4f59-b83b-035ca597a6aa",
   "metadata": {},
   "source": [
    "Consideramos once variables, diseñadas manualmente a partir de los datos. Estas son:\n",
    "* *release_date_timestamp.* Variable continua del tiempo de estreno\n",
    "* *release_date_month.* Variable entera que identifica el mes de estreno\n",
    "* *release_date_day.* Variable entera que identifica el dia de estreno\n",
    "* *num_top_production_companies.* Numero de productoras que son populares\n",
    "* *num_top_artists.* Numero de artistas que son populares\n",
    "* *ratio(runtime, budget).* Proporcion entre la duracion de la pelicula y el presupuesto\n",
    "* *num_artists.* Numero de artistas\n",
    "* *num_genres.* Numero de generos\n",
    "* *num_production_companies.* Numero de productoras \n",
    "* *prop(num_top_production_companies).* Proporcion de productoras que son populares\n",
    "* *prop(num_top_artists).* Proporcion de artistas que son populares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbcb96b3-50ea-48d7-b0f9-1742285bda9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer(func=<function feature_extractor at 0x000001E0240384C0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_extractor(X):\n",
    "    movies = X.copy()\n",
    "    movies[\"release_date_timestamp\"] = movies['release_date'].apply(lambda x: x.timestamp())\n",
    "    movies[\"release_date_month\"] = movies['release_date'].dt.month\n",
    "    movies[\"release_date_day\"] = movies['release_date'].dt.day\n",
    "    \n",
    "    top_companies = ['Warner Bros. Pictures', 'Universal Pictures', 'Columbia Pictures',\n",
    "       'Paramount', '20th Century Fox', 'Canal+', 'New Line Cinema',\n",
    "       'Metro-Goldwyn-Mayer', 'Lionsgate', 'Relativity Media',\n",
    "       'StudioCanal', 'Touchstone Pictures', 'Walt Disney Pictures',\n",
    "       'DreamWorks Pictures', 'Miramax']\n",
    "    \n",
    "    movies[\"num_top_production_companies\"] = movies[\"production_companies\"].apply(\n",
    "        lambda x: \n",
    "        sum(\n",
    "            [int(comp in str(x)) for comp in top_companies]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    top_artists = ['Samuel L. Jackson', 'Frank Welker', 'Nicolas Cage',\n",
    "       'Bruce Willis', 'Robert De Niro', 'Matt Damon', 'Liam Neeson',\n",
    "       'Willem Dafoe', 'Morgan Freeman', 'J.K. Simmons', 'Steve Buscemi',\n",
    "       'Johnny Depp', 'John Goodman', 'Paul Giamatti', 'Stanley Tucci',\n",
    "       'Woody Harrelson', 'Brad Pitt', 'Mickie McGowan', 'John Leguizamo',\n",
    "       'Robin Williams', 'Sylvester Stallone', 'Tom Hanks',\n",
    "       'Michael Papajohn', 'Nicole Kidman', 'Thomas Rosales Jr.',\n",
    "       'James Franco', 'Harrison Ford', 'Ben Affleck', 'Owen Wilson',\n",
    "       'Stephen Root', 'Julianne Moore', 'Ben Kingsley',\n",
    "       'Antonio Banderas', 'Anthony Hopkins', 'Alec Baldwin',\n",
    "       'Joe Chrest', 'Bill Hader', 'Richard Jenkins', 'John C. Reilly',\n",
    "       'Bill Murray', 'John Hurt', 'Elizabeth Banks', 'Michael Caine',\n",
    "       'Ewan McGregor', 'Keith David', 'Susan Sarandon',\n",
    "       'Fred Tatasciore', 'Bob Bergen', 'Scarlett Johansson',\n",
    "       'Keanu Reeves']\n",
    "    movies[\"num_top_artists\"] = movies[\"credits\"].apply(\n",
    "        lambda x: \n",
    "        sum(\n",
    "            [int(art in str(x).replace(\"-\", \" \")) for art in top_artists]\n",
    "        )\n",
    "    )\n",
    "    movies[\"ratio(runtime, budget)\"] = (movies[\"runtime\"]/(1+movies[\"budget\"]))\n",
    "    # Contar el número de actores/productoras/géneros.\n",
    "    movies[\"num_artists\"] = movies[\"credits\"].apply(\n",
    "        lambda x:\n",
    "        sum(\n",
    "            [len(str(x).split(\"-\"))]\n",
    "        )\n",
    "    )\n",
    "    movies[\"num_genres\"] = movies[\"genres\"].apply(\n",
    "        lambda x: len(str(x).split(\"-\"))\n",
    "    )\n",
    "    movies[\"num_production_companies\"] = movies[\"production_companies\"].apply(\n",
    "        lambda x: len(str(x).split(\"-\"))\n",
    "    )\n",
    "    movies[\"prop(num_top_production_companies)\"] = movies[\"num_top_production_companies\"]/(1+movies[\"num_production_companies\"])\n",
    "    movies[\"prop(num_top_artists)\"] = movies[\"num_top_artists\"]/(1+movies[\"num_artists\"])\n",
    "    return movies\n",
    "\n",
    "feature_tranformer = FunctionTransformer(feature_extractor)\n",
    "feature_tranformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ffb0b-07ff-48d1-a1a5-55fb506d857f",
   "metadata": {
    "cell_id": "ec9c0f8a2b044f858858ef3c3248c239",
    "deepnote_cell_height": 102,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "source": [
    "En esta subseccion se realizó una separacion de los datos, para entrenamiento y evaluacion. Adicionalmente, se contruyeron dos column transformers a partir de los datos, con el objetivo de preprocesar los datos vectorialmente. Finalmente, se añadieron once variables diseñadas manualmente con un FunctionTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0f8b6",
   "metadata": {
    "cell_id": "2d58aececbe34d6184477c8e3cfaa2e3",
    "deepnote_cell_height": 117.69999694824219,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Regresión\n",
    "\n",
    "### 3.1 Dummy y Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ec540-15e4-401c-bd20-ef3e7209cc28",
   "metadata": {},
   "source": [
    "A continuación, al igual que en la clasificación, se construyen los modelos \"Dummy\" y \"Baseline\" para la regresión. Estos servirán como referencia para verificar que el modelo encontrado predice mejor que un método que predice un valor contante (dummy) y un modelo simple (baseline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056070c-f805-4bcd-a28b-6c7bb83e7c0c",
   "metadata": {},
   "source": [
    "**Dummy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "234d3fe3-bda7-4305-b9d8-212341430689",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "y_pred_dummy = dummy_reg.predict(X_reg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619988c8-3457-462a-9acf-4826b11e1ee7",
   "metadata": {},
   "source": [
    "**Baseline:** Regresor Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f15c176",
   "metadata": {
    "cell_id": "faaf5b0b0d34479bad168c8dd4cbe508",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe_reg_baseline = Pipeline(\n",
    "    steps=[\n",
    "        (\"FunctionTransformer\", feature_tranformer),\n",
    "        (\"ColumnTransformer\", ct),\n",
    "        (\"reg\", linear_model.Lasso(alpha=0.1))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed694e87-8791-4c0e-9428-15ee9ac8268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('FunctionTransformer',\n",
       "                 FunctionTransformer(func=<function feature_extractor at 0x000001E0240384C0>)),\n",
       "                ('ColumnTransformer',\n",
       "                 ColumnTransformer(transformers=[('OneHot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['original_language',\n",
       "                                                   'clusters_keywords',\n",
       "                                                   'clusters_overview',\n",
       "                                                   'clusters_tagline']),\n",
       "                                                 ('MinMax', MinMaxScaler(),\n",
       "                                                  ['budget',\n",
       "                                                   'release_date_mon...\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x000001E026235C70>),\n",
       "                                                  'credits'),\n",
       "                                                 ('OneHot_split_production_companies',\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x000001E026235DF0>),\n",
       "                                                  'production_companies'),\n",
       "                                                 ('OneHot_split_keywords',\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x000001E026235B50>),\n",
       "                                                  'keywords')])),\n",
       "                ('reg', Lasso(alpha=0.1))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe_reg_baseline.fit(X_reg_train, y_reg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a49fab5-5dc5-4937-ab65-aad8e6ebdca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_reg_baseline = pipe_reg_baseline.predict(X_reg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed1017-a0d2-4dd4-9282-fb11414504b8",
   "metadata": {},
   "source": [
    "**Resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9719bf3-3546-4ac8-b63d-08691b17a176",
   "metadata": {},
   "source": [
    "Clasificador Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2627b4",
   "metadata": {
    "cell_id": "4e397759bca54254b536d998f20cbd08",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresor Dummy\n",
      "-0.0003707986340903968\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Regresor Dummy\\n\"+str(r2_score(y_reg_test, y_pred_dummy))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe307cb-7412-48e8-80f1-f0733fa90bad",
   "metadata": {},
   "source": [
    "Clasificador Baseline Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de91e419-e970-488b-8a03-da23566c0c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresor baseline: Lasso\n",
      "0.11560134261108834\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Regresor baseline: Lasso\\n\"+str(r2_score(y_reg_test, y_reg_baseline))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d457dd",
   "metadata": {
    "cell_id": "23ba7e6c56c841d8b2c11563ca64bf20",
    "deepnote_cell_height": 69.93333435058594,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Los resultados obtenidos fueron:\n",
    "```\n",
    "Dummy: -0.00037 r2\n",
    "Baseline (Lasso): 0.1156 r2\n",
    "```\n",
    "El modelo dummy predijo con un puntaje cercano a 0, esperable para un modelo aleatoreo; mientras que el baseline (regresor Lasso) obtuvo un puntaje de 0.11 de r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb1c44",
   "metadata": {
    "cell_id": "df491c3ed9704211be52235df236b889",
    "deepnote_cell_height": 61.69999694824219,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 3.2 Búsqueda del mejor modelo de Regresión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13922608-5be9-4a58-8a9a-f0f1c674e867",
   "metadata": {},
   "source": [
    "En esta sección el objetivo es encontrar un modelo mejor que el Baseline. Para esto se realizará una búsqueda del mejor modelo de regresión con la técnica de GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae67994-d4a5-427d-8f88-ca26c6be69b8",
   "metadata": {},
   "source": [
    "Antes de construir la grilla, de modo preliminar se presenta el comportamiento de los siguientes modelos de regresión:\n",
    "\n",
    "* Ridge\n",
    "* ElasticNet\n",
    "* Bagging (DecisionTree)\n",
    "* GradientBoosting\n",
    "* RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30d3b694-5c97-472a-a56e-ec11e0567b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipe_reg(model_class, params, params_selector):\n",
    "    model = model_class(**params)\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"FunctionTransformer\", feature_tranformer),\n",
    "            (\"ColumnTransformer\", ct),\n",
    "            (\"selector\", SelectPercentile(f_classif, **params_selector)),\n",
    "            ('reg', model)\n",
    "        ]\n",
    "     )\n",
    "    pipe.fit(X_reg_train, y_reg_train)\n",
    "    y_pred = pipe.predict(X_reg_test)\n",
    "    print(\n",
    "    f\"Clasificador: {model_class.__name__}\\n\"+str(r2_score(y_reg_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "36e5c1aa-03c0-4b1a-b26b-1a9d55c3d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: Ridge\n",
      "0.5370160239536188\n",
      "CPU times: total: 22.6 s\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_reg(\n",
    "    linear_model.Ridge,\n",
    "    params={\n",
    "        \"alpha\":2,\n",
    "        'tol':1e-5\n",
    "    },\n",
    "    params_selector={'percentile': 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9a66111-8765-4422-8837-cfc75d38163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: ElasticNet\n",
      "0.3247377660809302\n",
      "CPU times: total: 57 s\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#en gridsearch usar este en vez de los dos anteriores, e incluir l1_ratio=1 para Lasso\n",
    "test_pipe_reg( \n",
    "    linear_model.ElasticNet,\n",
    "    params={\n",
    "        \"alpha\":0.5,\n",
    "        'tol':1e-4,\n",
    "        'l1_ratio':0.5\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7415036-4f1d-4cf7-8cda-364cdc3cf4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: BaggingRegressor\n",
      "0.5338382663146124\n",
      "CPU times: total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_reg( \n",
    "    BaggingRegressor,\n",
    "    params={\n",
    "        'base_estimator': DecisionTreeRegressor(),\n",
    "        'n_estimators': 10,\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3dc63a29-bafb-4b98-ae64-f831a89d8774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: GradientBoostingRegressor\n",
      "0.5769260305671147\n",
      "CPU times: total: 35 s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_reg( \n",
    "    GradientBoostingRegressor,\n",
    "    params={\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a5c5c-a8d1-4bce-886c-3c91694bd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_pipe_reg( \n",
    "    RandomForestRegressor,\n",
    "    params={\n",
    "        'max_depth': None\n",
    "    },\n",
    "    params_selector={'percentile': 95}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82503a-f04c-465b-a3a1-4c0184df83c4",
   "metadata": {},
   "source": [
    "A partir de los regresores presentados, se construye la grilla de búsqueda para encontrar el mejor regresor con los mejores hiperparámetros:\n",
    "\n",
    "1. **Ridge**:\n",
    "    * alpha: [1, 1.5, 2]\n",
    "    * tol: [5e-5, 1e-5, 5e-6]\n",
    "    * random_state: 42\n",
    "    * ColumnTransformer: [ct, ct_wo_bow]\n",
    "2. **ElasticNet**:\n",
    "    * alpha: [0.45, 0.5, 0.55]\n",
    "    * l1_ratio: [0.75, 0.9, 0.95]\n",
    "    * tol: [0.0005, 1e-4, 0.00005]\n",
    "    * random_state: 42\n",
    "    * ColumnTransformer: [ct, ct_wo_bow]\n",
    "3. **Bagging(DecisionTreeRegressor)**:\n",
    "    * n_estimators: [10, 15, 20]\n",
    "    * random_state: 42\n",
    "    * ColumnTransformer: [ct, ct_wo_bow]\n",
    "4. **GradientBoosting**:\n",
    "    * learning_rate: [0.05, 0.1, 0.2]\n",
    "    * n_estimators: [150, 200, 250]\n",
    "    * random_state: 42\n",
    "    * ColumnTransformer: [ct, ct_wo_bow]\n",
    "5. **RandomForest**:\n",
    "    * n_estimators: [50, 75, 100]\n",
    "    * max_depth: [8, 10, 12]\n",
    "    * random_state: 42\n",
    "    * ColumnTransformer: [ct, ct_wo_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ca580-ba27-49e0-b225-7b70b5ce051a",
   "metadata": {},
   "source": [
    "**Definición de la Grilla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51453725-b27b-4e50-a933-14c212d35823",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"FunctionTransformer\", feature_tranformer),\n",
    "            (\"ColumnTransformer\", ct),\n",
    "            (\"reg\", linear_model.Lasso(alpha=0.1))\n",
    "        ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3823b8",
   "metadata": {
    "cell_id": "cfc6786c0598444bb8070990453da397",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código GridSearch\n",
    "param_grid = [\n",
    "    # grilla 1: Ridge\n",
    "    {\n",
    "        \"reg\": [linear_model.Ridge(random_state=42)],\n",
    "        \"reg__alpha\": [1, 1.5, 2],\n",
    "        \"reg__tol\": [5e-5, 1e-5, 5e-6],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 2: ElasticNet\n",
    "    {\n",
    "        \"reg\": [linear_model.ElasticNet(random_state=42)],\n",
    "        \"reg__alpha\": [0.45, 0.5, 0.55],\n",
    "        \"reg__l1_ratio\": [0.75, 0.9, 0.95],\n",
    "        \"reg__tol\": [0.0005, 1e-4, 0.00005],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 3: BaggingRegressor\n",
    "    {\n",
    "        \"reg\": [BaggingRegressor(base_estimator=DecisionTreeRegressor(), random_state=42)],\n",
    "        \"reg__n_estimators\": [10, 15, 20],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 4: GradientBoosting\n",
    "    {\n",
    "        \"reg\": [GradientBoostingRegressor(random_state=42)],\n",
    "        \"reg__learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"reg__n_estimators\": [150, 200, 250],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 5: RandomForest\n",
    "    {\n",
    "        \"reg\": [RandomForestRegressor(random_state=42)],\n",
    "        \"reg__n_estimators\": [50, 75, 100],\n",
    "        \"reg__max_depth\": [8, 10, 12],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d536fbd-d566-46d4-8520-626d7210cb3d",
   "metadata": {},
   "source": [
    "**GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75ceb994-670e-4c97-94b9-c71b9c9cb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid, n_jobs=-1, scoring='r2', verbose=10, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95efa281-fa20-476e-81f7-79f57a9a068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_reg_train, y_reg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a1a1589b-4428-4ed1-b3ae-fe00fd6ccc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193961795515415"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c805a-726b-4229-9e68-4161bb5c34a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ColumnTransformer': ColumnTransformer(transformers=[('OneHot',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['original_language', 'clusters_keywords',\n",
      "                                  'clusters_overview', 'clusters_tagline']),\n",
      "                                ('MinMax', MinMaxScaler(),\n",
      "                                 ['budget', 'release_date_month',\n",
      "                                  'release_date_day',\n",
      "                                  'num_top_production_companies',\n",
      "                                  'num_top_artists', 'ratio(runtime, budget)',\n",
      "                                  'num_artists', 'num_genres',\n",
      "                                  'num_product...\n",
      "                                ('OneHot_split_credits',\n",
      "                                 CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000123B09DBF70>),\n",
      "                                 'credits'),\n",
      "                                ('OneHot_split_production_companies',\n",
      "                                 CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000123B09E60A0>),\n",
      "                                 'production_companies'),\n",
      "                                ('OneHot_split_keywords',\n",
      "                                 CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000123B09E6130>),\n",
      "                                 'keywords')]), 'reg': GradientBoostingRegressor(n_estimators=250, random_state=42), 'reg__learning_rate': 0.1, 'reg__n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "best_pipe = gs.best_estimator_\n",
    "#best_pipe.get_params()\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c387ed-b86e-42c4-a652-49556b1e180a",
   "metadata": {},
   "source": [
    "### Mejor modelo\n",
    "\n",
    "Regresor: *GradientBoostingRegressor*\n",
    "\n",
    "Hiperparámetros:\n",
    "\n",
    "    random_state: 42\n",
    "    learning_rate: 0.1\n",
    "    n_estimators: 250\n",
    "    ColumnTransformer: ct_wo_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b02bec-6ddb-4246-bff1-b663e3978d71",
   "metadata": {},
   "source": [
    "**Puntaje $R^2$ en conjunto test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6f6317c-0335-4a5e-b304-0ca7b0f33638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion: GradientBoostingRegressor\n",
      "0.5921498826735858\n"
     ]
    }
   ],
   "source": [
    "rgr_pipe = Pipeline(\n",
    "    steps=[\n",
    "            (\"FunctionTransformer\", feature_tranformer),\n",
    "            (\"ColumnTransformer\", ct_wo_bow),\n",
    "            (\"selector\", SelectPercentile(f_classif, percentile=100)),\n",
    "            (\"reg\", GradientBoostingRegressor(learning_rate= 0.1, n_estimators=250, random_state=42))\n",
    "        ]\n",
    "     )\n",
    "rgr_pipe.fit(X_reg_train, y_reg_train)\n",
    "y_pred = rgr_pipe.predict(X_reg_test)\n",
    "print(f\"Regresion: GradientBoostingRegressor\\n\"+str(r2_score(y_reg_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f6eb1-09a9-4f84-94c5-c251344d6620",
   "metadata": {},
   "source": [
    "**Análisis de Resultados**\n",
    "```\n",
    "Dummy: -0.00037 r2\n",
    "Baseline (Lasso): 0.1156 r2\n",
    "Candidato (GradientBoosting): 0.59215 r2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982cb69-07d7-48d3-bf32-c1e0b1bff129",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f005940-c7a2-4699-a99f-829e8a069880",
   "metadata": {},
   "source": [
    "Cargar los datos de la competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5165c371",
   "metadata": {
    "cell_id": "b00b9baef48947d9abcfb6972bdaa3aa",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateFiles(predict_data, clf_pipe, rgr_pipe):\n",
    "    \"\"\"Genera los archivos a subir en CodaLab\n",
    "\n",
    "    Input\n",
    "    predict_data: Dataframe con los datos de entrada a predecir\n",
    "    clf_pipe: pipeline del clf\n",
    "    rgr_pipe: pipeline del rgr\n",
    "\n",
    "    Ouput\n",
    "    archivo de txt\n",
    "    \"\"\"\n",
    "    y_pred_clf = clf_pipe.predict(predict_data)\n",
    "    y_pred_rgr = rgr_pipe.predict(predict_data)\n",
    "    \n",
    "    with open('./predictions_clf.txt', 'w') as f:\n",
    "        for item in y_pred_clf:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open('./predictions_rgr.txt', 'w') as f:\n",
    "        for item in y_pred_rgr:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with ZipFile('predictions.zip', 'w') as zipObj2:\n",
    "        zipObj2.write('predictions_rgr.txt')\n",
    "        zipObj2.write('predictions_clf.txt')\n",
    "\n",
    "    os.remove(\"predictions_rgr.txt\")\n",
    "    os.remove(\"predictions_clf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c75ab3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusters_keywords</th>\n",
       "      <th>clusters_overview</th>\n",
       "      <th>clusters_tagline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>656 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clusters_keywords clusters_overview clusters_tagline\n",
       "0                  11                 1                8\n",
       "1                   9                 7               11\n",
       "2                   5                 5                2\n",
       "3                  14                 5                3\n",
       "4                  13                11                3\n",
       "..                ...               ...              ...\n",
       "651                 9                11                0\n",
       "652                 1                 0                0\n",
       "653                 9                 1                5\n",
       "654                14                11                8\n",
       "655                 1                 7                8\n",
       "\n",
       "[656 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pickle.load(open(\"test.pickle\", \"rb\"))\n",
    "test[\"release_date\"] = test[\"release_date\"].apply(pd.to_datetime)\n",
    "test = test.fillna(\"\")\n",
    "test = test.reset_index(drop=True)\n",
    "test_clusters_BERT = pickle.load(open(\"test_clusters_BERT.pickle\", \"rb\"))\n",
    "test = test.merge(test_clusters_BERT, how=\"left\", on=\"title\")\n",
    "test[\"clusters_keywords clusters_overview clusters_tagline\".split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf22c26-3898-469b-807d-1c4955bedbb5",
   "metadata": {},
   "source": [
    "Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c382b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = test\n",
    "generateFiles(predict_data, rgr_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce5d7d1",
   "metadata": {
    "cell_id": "00025-2acf9c12-da85-4c1f-add5-f2b0f600177f",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Conclusiones Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996db4c2",
   "metadata": {
    "cell_id": "00026-15c07b20-0e16-48fa-bf3c-33aeb2c4c1db",
    "deepnote_cell_height": 51.53334045410156,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "En la presente parte del proyecto se procedió con resolver el problema de regresión de las ganancias esperadas de las películas. Para esto, una vez preparados los datos, se siguieron los siguientes 3 pasos: (1) Modelos de referencia, (2) Gridsearch y (3) Predicción.\n",
    "\n",
    "En la etapa (1) se procedió a definir dos modelos básicos de referencia, estos son el *Dummy* y *Baseline*. Esos modelos fueron generados para tener un punto de referencia sobre qué esperar cuando se busque un modelo adecuado, con hiperparámetros ajustados mediante GridSearch. El modelo dummy genera una predicción igual a la media para todos los valores, mientras que el regresor baseline es Lasso, un modelo lineal. Los regresores obtuvieron un puntaje $R^2$ de -0.00037 y 0.1156, para el dummy y el baseline, respectivamente.\n",
    "\n",
    "En el paso (2) se construyó la grilla de búsqueda de regresores, que se utilizó para encontrar el mejor regresor mediante el mejor puntaje $R^2$. Despues de probar variados modelos de forma individua, los métodos escogidos para ejecutar el GridSearch fueron: Ridge, ElasticNet, Bagging(DecisionTree), GradientBoosting y RandomForest. Luego de realizada la búsqueda, el módelo con mejor desempeño fue GradientBoosting, obteniendo un puntaje $R^2$ de 0.59 en el conjunto de testeo, superando en gran medida los modelos Dummy y Baseline.\n",
    "\n",
    "Posteriormente, en la etapa (3) se predicen datos nuevos a los que no se tienen acceso al momento de generar los modelos. Esto se hace subiendo el código a CodaLab donde distintos equipos compiten para obtener el mejor puntaje prediciendo datos nuevos. Para esto, se utiliza el modelo que reportó GridSearch para predecir el conjunto de la competencia, donde se obtuvo un puntaje $R^2$ de 0.88. \n",
    "\n",
    "A modo de conclusión, se pudo encontrar un modelo acorde con sus hiperparámetros ajustados mediante GridSearch, con el objetivo de generar una herramienta que permita precedir las ganancias de una película, según distintas características de esta. El resultado es aceptable, considerando que no se entrenó con las valoraciones de las películas en esta parte, por lo que se puede concluir que sí hay características en las películas que permiten una regresión adecuada. Por otro lado, el método ganador resulto un regresor de ensamblaje, el cual utiliza múltiples ejecuciones de modelos simples (como árboles de decisión), que se vió en cátedra que era una alternativa poderosa para predecir.\n",
    "\n",
    "El resultado podría mejorar con una búsqueda más fina respecto a los hiperparámetros del modelo seleccionado, lo que podría realizarse con un GridSearch con mayores recursos computacionales y de tiempo. Otro espacio de mejora es realizar acciones adicionales de FeatureEngineering con respecto a los datos de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "dbddc0f3-10b8-4160-bc27-ac993196164c",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

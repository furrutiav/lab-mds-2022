{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e96b59b",
   "metadata": {
    "cell_id": "00006-84a35c5d-0758-4cbb-b2ca-b182898b80d0",
    "deepnote_cell_height": 295.8833312988281,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "\n",
    "# Proyecto\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- Sebastian Avendaño\n",
    "- Felipe Urrutia\n",
    "\n",
    "- \\<Nombre de usuarios en Codalab\\>\n",
    "\n",
    "- \\<Nombre del Equipo en Codalab\\>\n",
    "\n",
    "### Link de repositorio de GitHub: https://github.com/furrutiav/lab-mds-2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8db88-52a2-47d9-8d4f-71e4fe81f833",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Librerías Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c27824f-57d0-4eea-ab8e-1db9ad9fde73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (8.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (from pyarrow) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "# Carga y Preparación de los datos\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install pyarrow\n",
    "\n",
    "# EDA\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975667a2",
   "metadata": {
    "cell_id": "00008-6607fdcd-a35f-4e75-9b46-da3b181c1551",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "## 2. Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc572b58",
   "metadata": {},
   "source": [
    "#### Carga y Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7863e",
   "metadata": {},
   "source": [
    "- Cargar los datos con Pandas y fusionar por `id`.\n",
    "- Eliminar columnas `'poster_path'`, `'backdrop_path'`, `'recommendations'`.\n",
    "- Filtrar ejemplos con `revenue` igual a 0.\n",
    "- Filtrar ejemplos con `release_date` y `runtime` nulos.\n",
    "- Convertir fechas de release_date a `pd.DateTime`.\n",
    "- Conservar solo los ejemplos con `status` `\"Released\"`.\n",
    "- Rellenar valores nulos categóricos y de texto con `''`.\n",
    "- Discretizar `vote_average` a los siguientes bins y guardar los resultados en la columna `label`: \n",
    "  - (0, 5]: `'Negative'`\n",
    "  - (5, 6]: `'Mixed'`\n",
    "  - (6, 7]: `'Mostly Positive'`\n",
    "  - (7, 8]: `'Positive'`\n",
    "  - (8, 10]: `'Very Positive'`\n",
    "- Eliminar la columna `vote_average` e `id`\n",
    "- Renombrar la columna `revenue` por `target`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161be2a",
   "metadata": {},
   "source": [
    "Cargar los datos con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9dd483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos: train_numerical_features.parquet y train_text_features.parquet\n",
    "train_numerical_features = pd.read_parquet('train_numerical_features.parquet').set_index(\"id\")\n",
    "train_text_features = pd.read_parquet('train_text_features.parquet').set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f1cec",
   "metadata": {},
   "source": [
    "Fusionar por id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d257939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_numerical_features, train_text_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202cca5",
   "metadata": {},
   "source": [
    "Eliminar columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ef5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe140d7",
   "metadata": {},
   "source": [
    "Eliminar columnas 'poster_path', 'backdrop_path', 'recommendations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c150a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['poster_path', 'backdrop_path', 'recommendations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fd31c",
   "metadata": {},
   "source": [
    "Filtrar ejemplos con revenue igual a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f2630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"revenue\"]>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fa989",
   "metadata": {},
   "source": [
    "Filtrar ejemplos con release_date y runtime nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26c07ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"release_date\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f473d059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"runtime\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7873aba",
   "metadata": {},
   "source": [
    "Convertir fechas de release_date a pd.DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecde65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"release_date\"] = df[\"release_date\"].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad39d9",
   "metadata": {},
   "source": [
    "Conservar solo los ejemplos con status \"Released\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f12ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"status\"] == \"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdfaf7",
   "metadata": {},
   "source": [
    "Rellenar valores nulos categóricos y de texto con ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05dd5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[train_text_features.columns.tolist()] = df[train_text_features.columns.tolist()].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fb62e",
   "metadata": {},
   "source": [
    "Discretizar vote_average a los siguientes bins y guardar los resultados en la columna label:\n",
    "\n",
    "    (0, 5]: 'Negative'\n",
    "    (5, 6]: 'Mixed'\n",
    "    (6, 7]: 'Mostly Positive'\n",
    "    (7, 8]: 'Positive'\n",
    "    (8, 10]: 'Very Positive'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b7c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = pd.cut(df['vote_average'], \n",
    "       bins=[0,5,6,7,8,10], \n",
    "       labels=[\"Negative\", \"Mixed\", \"Mostly Positive\", \"Positive\", \"Very Positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b637862",
   "metadata": {},
   "source": [
    "Eliminar la columna vote_average e id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50789594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"vote_average\")\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ea6b5",
   "metadata": {},
   "source": [
    "Renombrar la columna revenue por target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44993017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"revenue\": \"target\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892709c2",
   "metadata": {},
   "source": [
    "Cargamos los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d44dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_BERT = pickle.load(open(\"clusters_BERT.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eafd4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>target</th>\n",
       "      <th>runtime</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>credits</th>\n",
       "      <th>genres</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>release_date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>label</th>\n",
       "      <th>clusters_keywords</th>\n",
       "      <th>clusters_overview</th>\n",
       "      <th>clusters_tagline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fantastic Beasts: The Secrets of Dumbledore</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>400000000.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Return to the magic.</td>\n",
       "      <td>Jude Law-Eddie Redmayne-Mads Mikkelsen-Ezra Mi...</td>\n",
       "      <td>Fantasy-Adventure-Action</td>\n",
       "      <td>en</td>\n",
       "      <td>Professor Albus Dumbledore knows the powerful ...</td>\n",
       "      <td>Warner Bros. Pictures-Heyday Films</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>magic-curse-fantasy world-wizard-magical creat...</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sonic the Hedgehog 2</td>\n",
       "      <td>110000000.0</td>\n",
       "      <td>393000000.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Welcome to the next level.</td>\n",
       "      <td>James Marsden-Ben Schwartz-Tika Sumpter-Natash...</td>\n",
       "      <td>Action-Adventure-Family-Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>After settling in Green Hills Sonic is eager t...</td>\n",
       "      <td>Original Film-Blur Studio-Marza Animation Plan...</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>sequel-based on video game-hedgehog-live actio...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lost City</td>\n",
       "      <td>74000000.0</td>\n",
       "      <td>164289828.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>The adventure is real. The heroes are not.</td>\n",
       "      <td>Sandra Bullock-Channing Tatum-Daniel Radcliffe...</td>\n",
       "      <td>Action-Adventure-Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>A reclusive romance novelist was sure nothing ...</td>\n",
       "      <td>Paramount-Fortis Films-3dot Productions-Exhibi...</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>duringcreditsstinger</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morbius</td>\n",
       "      <td>75000000.0</td>\n",
       "      <td>161000000.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>A new Marvel legend arrives.</td>\n",
       "      <td>Jared Leto-Matt Smith-Adria Arjona-Jared Harri...</td>\n",
       "      <td>Action-Science Fiction-Fantasy</td>\n",
       "      <td>en</td>\n",
       "      <td>Dangerously ill with a rare blood disorder and...</td>\n",
       "      <td>Columbia Pictures-Avi Arad Productions-Matt To...</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>vampire-based on comic</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uncharted</td>\n",
       "      <td>120000000.0</td>\n",
       "      <td>400780000.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Fortune favors the bold.</td>\n",
       "      <td>Tom Holland-Mark Wahlberg-Sophia Ali-Tati Gabr...</td>\n",
       "      <td>Action-Adventure</td>\n",
       "      <td>en</td>\n",
       "      <td>A young street-smart Nathan Drake and his wise...</td>\n",
       "      <td>Columbia Pictures-Atlas Entertainment-PlayStat...</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>treasure-treasure hunt-based on video game-dlb</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>Amistad</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>44229441.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Freedom is not given. It is our right at birth...</td>\n",
       "      <td>Morgan Freeman-Nigel Hawthorne-Anthony Hopkins...</td>\n",
       "      <td>Drama-History-Mystery</td>\n",
       "      <td>en</td>\n",
       "      <td>In 1839 the slave ship Amistad set sail from C...</td>\n",
       "      <td>DreamWorks Pictures</td>\n",
       "      <td>1997-12-10</td>\n",
       "      <td>cuba-mutiny-slavery-sentence-historical figure...</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>Home Alone</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>476684675.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>A family comedy without the family.</td>\n",
       "      <td>Macaulay Culkin-Joe Pesci-Daniel Stern-John He...</td>\n",
       "      <td>Comedy-Family</td>\n",
       "      <td>en</td>\n",
       "      <td>Eight-year-old Kevin McCallister makes the mos...</td>\n",
       "      <td>Hughes Entertainment-20th Century Fox</td>\n",
       "      <td>1990-11-16</td>\n",
       "      <td>holiday-burglar-slapstick-little boy-family re...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>Ip Man: The Final Fight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3967001.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>Anthony Wong-Anita Yuen-Gillian Chung-Jordan C...</td>\n",
       "      <td>Action-Drama</td>\n",
       "      <td>cn</td>\n",
       "      <td>In postwar Hong Kong legendary Wing Chun grand...</td>\n",
       "      <td>Emperor Motion Pictures-Cinemasia-National Art...</td>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>biography</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>A Rainy Day in New York</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>23800000.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Love In Spring.</td>\n",
       "      <td>Timothée Chalamet-Elle Fanning-Selena Gomez-Ju...</td>\n",
       "      <td>Comedy-Romance</td>\n",
       "      <td>en</td>\n",
       "      <td>Two young people arrive in New York to spend a...</td>\n",
       "      <td>Gravier Productions-Perdido Productions-FilmNa...</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>new york city</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>The Internship</td>\n",
       "      <td>58000000.0</td>\n",
       "      <td>44000000.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Hiring them was a brilliant mistake.</td>\n",
       "      <td>Vince Vaughn-Owen Wilson-Rose Byrne-Aasif Mand...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>Two recently laid-off men in their 40s try to ...</td>\n",
       "      <td>TSG Entertainment-Regency Enterprises-Wild Wes...</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>mattress shop-job interview-rivalry-loss of jo...</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6451 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title       budget       target  \\\n",
       "0     Fantastic Beasts: The Secrets of Dumbledore  200000000.0  400000000.0   \n",
       "1                            Sonic the Hedgehog 2  110000000.0  393000000.0   \n",
       "2                                   The Lost City   74000000.0  164289828.0   \n",
       "3                                         Morbius   75000000.0  161000000.0   \n",
       "4                                       Uncharted  120000000.0  400780000.0   \n",
       "...                                           ...          ...          ...   \n",
       "6446                                      Amistad   36000000.0   44229441.0   \n",
       "6447                                   Home Alone   18000000.0  476684675.0   \n",
       "6448                      Ip Man: The Final Fight          0.0    3967001.0   \n",
       "6449                      A Rainy Day in New York   25000000.0   23800000.0   \n",
       "6450                               The Internship   58000000.0   44000000.0   \n",
       "\n",
       "     runtime    status                                            tagline  \\\n",
       "0      142.0  Released                               Return to the magic.   \n",
       "1      122.0  Released                         Welcome to the next level.   \n",
       "2      112.0  Released         The adventure is real. The heroes are not.   \n",
       "3      105.0  Released                       A new Marvel legend arrives.   \n",
       "4      116.0  Released                           Fortune favors the bold.   \n",
       "...      ...       ...                                                ...   \n",
       "6446   155.0  Released  Freedom is not given. It is our right at birth...   \n",
       "6447   103.0  Released                A family comedy without the family.   \n",
       "6448   100.0  Released                                                      \n",
       "6449    92.0  Released                                    Love In Spring.   \n",
       "6450   119.0  Released               Hiring them was a brilliant mistake.   \n",
       "\n",
       "                                                credits  \\\n",
       "0     Jude Law-Eddie Redmayne-Mads Mikkelsen-Ezra Mi...   \n",
       "1     James Marsden-Ben Schwartz-Tika Sumpter-Natash...   \n",
       "2     Sandra Bullock-Channing Tatum-Daniel Radcliffe...   \n",
       "3     Jared Leto-Matt Smith-Adria Arjona-Jared Harri...   \n",
       "4     Tom Holland-Mark Wahlberg-Sophia Ali-Tati Gabr...   \n",
       "...                                                 ...   \n",
       "6446  Morgan Freeman-Nigel Hawthorne-Anthony Hopkins...   \n",
       "6447  Macaulay Culkin-Joe Pesci-Daniel Stern-John He...   \n",
       "6448  Anthony Wong-Anita Yuen-Gillian Chung-Jordan C...   \n",
       "6449  Timothée Chalamet-Elle Fanning-Selena Gomez-Ju...   \n",
       "6450  Vince Vaughn-Owen Wilson-Rose Byrne-Aasif Mand...   \n",
       "\n",
       "                              genres original_language  \\\n",
       "0           Fantasy-Adventure-Action                en   \n",
       "1     Action-Adventure-Family-Comedy                en   \n",
       "2            Action-Adventure-Comedy                en   \n",
       "3     Action-Science Fiction-Fantasy                en   \n",
       "4                   Action-Adventure                en   \n",
       "...                              ...               ...   \n",
       "6446           Drama-History-Mystery                en   \n",
       "6447                   Comedy-Family                en   \n",
       "6448                    Action-Drama                cn   \n",
       "6449                  Comedy-Romance                en   \n",
       "6450                          Comedy                en   \n",
       "\n",
       "                                               overview  \\\n",
       "0     Professor Albus Dumbledore knows the powerful ...   \n",
       "1     After settling in Green Hills Sonic is eager t...   \n",
       "2     A reclusive romance novelist was sure nothing ...   \n",
       "3     Dangerously ill with a rare blood disorder and...   \n",
       "4     A young street-smart Nathan Drake and his wise...   \n",
       "...                                                 ...   \n",
       "6446  In 1839 the slave ship Amistad set sail from C...   \n",
       "6447  Eight-year-old Kevin McCallister makes the mos...   \n",
       "6448  In postwar Hong Kong legendary Wing Chun grand...   \n",
       "6449  Two young people arrive in New York to spend a...   \n",
       "6450  Two recently laid-off men in their 40s try to ...   \n",
       "\n",
       "                                   production_companies release_date  \\\n",
       "0                    Warner Bros. Pictures-Heyday Films   2022-04-06   \n",
       "1     Original Film-Blur Studio-Marza Animation Plan...   2022-03-30   \n",
       "2     Paramount-Fortis Films-3dot Productions-Exhibi...   2022-03-24   \n",
       "3     Columbia Pictures-Avi Arad Productions-Matt To...   2022-03-30   \n",
       "4     Columbia Pictures-Atlas Entertainment-PlayStat...   2022-02-10   \n",
       "...                                                 ...          ...   \n",
       "6446                                DreamWorks Pictures   1997-12-10   \n",
       "6447              Hughes Entertainment-20th Century Fox   1990-11-16   \n",
       "6448  Emperor Motion Pictures-Cinemasia-National Art...   2013-03-22   \n",
       "6449  Gravier Productions-Perdido Productions-FilmNa...   2019-07-26   \n",
       "6450  TSG Entertainment-Regency Enterprises-Wild Wes...   2013-06-07   \n",
       "\n",
       "                                               keywords            label  \\\n",
       "0     magic-curse-fantasy world-wizard-magical creat...  Mostly Positive   \n",
       "1     sequel-based on video game-hedgehog-live actio...         Positive   \n",
       "2                                  duringcreditsstinger  Mostly Positive   \n",
       "3                                vampire-based on comic  Mostly Positive   \n",
       "4        treasure-treasure hunt-based on video game-dlb         Positive   \n",
       "...                                                 ...              ...   \n",
       "6446  cuba-mutiny-slavery-sentence-historical figure...  Mostly Positive   \n",
       "6447  holiday-burglar-slapstick-little boy-family re...         Positive   \n",
       "6448                                          biography  Mostly Positive   \n",
       "6449                                      new york city  Mostly Positive   \n",
       "6450  mattress shop-job interview-rivalry-loss of jo...  Mostly Positive   \n",
       "\n",
       "     clusters_keywords clusters_overview clusters_tagline  \n",
       "0                    8                14               11  \n",
       "1                    7                14               11  \n",
       "2                   10                13               13  \n",
       "3                    7                10                4  \n",
       "4                   14                14                6  \n",
       "...                ...               ...              ...  \n",
       "6446                13                 0                9  \n",
       "6447                 9                 7               13  \n",
       "6448                 5                 1               -1  \n",
       "6449                 5                 9               13  \n",
       "6450                 9                12                2  \n",
       "\n",
       "[6451 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(clusters_BERT, how=\"left\", on=\"title\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa072c",
   "metadata": {
    "cell_id": "00011-95957584-71f1-4669-a6e5-9b8ac7b8d4e0",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Preprocesamiento, Holdout y Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e450ed7",
   "metadata": {},
   "source": [
    "#### ColumnTransformer y Holdout\n",
    "\n",
    "*Esta sección consiste en generar los distintos pasos para preparar sus datos con el fin de luego poder crear su modelo.*\n",
    "\n",
    "Generar un ColumnTransformer que:\n",
    "\n",
    "- Preprocese datos categóricos y ordinales.\n",
    "- Escale/estandarice datos numéricos.\n",
    "- Codifique texto.\n",
    "\n",
    "Luego, pruebe las transformaciones utilizando `fit_transform` y `get_feature_names out`.\n",
    "\n",
    "Posteriormente, ejecute un Holdout que le permita más adelante evaluar los modelos. **Recuerde eliminar los target y las labels del dataset antes de dividirlo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a208e17c",
   "metadata": {
    "cell_id": "00012-f977f172-2409-44c1-9ff4-118d043985cc",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166470,
    "source_hash": "2dc8e0f4"
   },
   "outputs": [],
   "source": [
    "## Código Holdout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b38b7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf, y_clf = df.drop(columns=[\"target\", \"label\"]), df[\"label\"]\n",
    "X_reg, y_reg = df.drop(columns=[\"target\", \"label\"]), df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91249544",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(X_clf, y_clf, test_size=0.20, random_state=23)\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.20, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14ba6691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (from nltk) (8.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebastian\\.conda\\envs\\mds7202\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sebastian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98720dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9024bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Código ColumnTransformer\n",
    "atributos_minmax = [\n",
    "    \"budget\",\n",
    "    \"release_date_month\",\n",
    "    \"release_date_day\",\n",
    "    \"num_top_production_companies\",\n",
    "    \"num_top_artists\",\n",
    "    \"ratio(runtime, budget)\",\n",
    "    \"num_artists\",\n",
    "    \"num_genres\",\n",
    "    \"num_production_companies\",\n",
    "    \"prop(num_top_production_companies)\",\n",
    "    \"prop(num_top_artists)\"\n",
    "]\n",
    "atributos_st = [\n",
    "    \"runtime\",\n",
    "    \"release_date_timestamp\",\n",
    "]\n",
    "\n",
    "atributos_onehot = [\n",
    "    \"original_language\",\n",
    "    \"clusters_keywords\",\n",
    "    \"clusters_overview\",\n",
    "    \"clusters_tagline\"\n",
    "]\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Definimos un tokenizador con Stemming\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc.lower())\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]\n",
    "    \n",
    "class SplitTokenizer:\n",
    "    def __init__(self, char=\"-\", col=\"\"):\n",
    "        self.char = char\n",
    "        self.col = col\n",
    "    def __call__(self, doc):\n",
    "        if self.col == \"production_companies\":\n",
    "            return doc.replace(\" \", \"_\").replace(\"Metro-Goldwyn-Mayer\", \"MGM\").split(self.char)\n",
    "        elif self.col == \"credits\":\n",
    "            tokens = doc.split(\"-\")\n",
    "            real_tokens = []\n",
    "            for i, tk in enumerate(tokens[:-1]):\n",
    "                if len(tokens[i+1].split()) == 1: tk = f\"{tk} {tokens[i+1]}\"\n",
    "                if len(tk.split())>1: real_tokens.append(tk)\n",
    "            return real_tokens\n",
    "        else:\n",
    "            return doc.replace(\" \", \"_\").split(self.char)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    (\"OneHot\", \n",
    "     OneHotEncoder(handle_unknown=\"ignore\"), \n",
    "     atributos_onehot\n",
    "    ),\n",
    "    (\"MinMax\", \n",
    "     MinMaxScaler(), \n",
    "     atributos_minmax\n",
    "    ),\n",
    "    (\"Standard\", \n",
    "     StandardScaler(), \n",
    "     atributos_st\n",
    "    ),\n",
    "    (\"BOW1\", \n",
    "     CountVectorizer(tokenizer= StemmerTokenizer()), \n",
    "     \"overview\"\n",
    "    ),\n",
    "    (\"OneHot_split_genres\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"genres\"\n",
    "    ),\n",
    "    (\"BOW2\", \n",
    "     CountVectorizer(tokenizer= StemmerTokenizer()), \n",
    "     \"tagline\"\n",
    "    ),\n",
    "    (\"OneHot_split_credits\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"credits\")), \n",
    "     \"credits\"\n",
    "    ),\n",
    "    (\"OneHot_split_production_companies\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"production_companies\")), \n",
    "     \"production_companies\"\n",
    "    ),\n",
    "    (\"OneHot_split_keywords\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"keywords\"\n",
    "    ),\n",
    "])\n",
    "\n",
    "ct_wo_bow = ColumnTransformer([\n",
    "    (\"OneHot\", \n",
    "     OneHotEncoder(handle_unknown=\"ignore\"), \n",
    "     atributos_onehot\n",
    "    ),\n",
    "    (\"MinMax\", \n",
    "     MinMaxScaler(), \n",
    "     atributos_minmax\n",
    "    ),\n",
    "    (\"Standard\", \n",
    "     StandardScaler(), \n",
    "     atributos_st\n",
    "    ),\n",
    "    (\"OneHot_split_genres\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"genres\"\n",
    "    ),\n",
    "    (\"OneHot_split_credits\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"credits\")), \n",
    "     \"credits\"\n",
    "    ),\n",
    "    (\"OneHot_split_production_companies\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer(col=\"production_companies\")), \n",
    "     \"production_companies\"\n",
    "    ),\n",
    "    (\"OneHot_split_keywords\", \n",
    "     CountVectorizer(tokenizer= SplitTokenizer()), \n",
    "     \"keywords\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4fa7c",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "Adicionalmente puede generar una nueva transformación que genere nuevas features y que se aplique antes del ColumnTransformer dentro del pipeline de los modelos. Investigar [`FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) para ver como implementar una transformación a partir de una función que tome un dataframe y entregue uno distinto en la salida.\n",
    "\n",
    "- Encodear ciclicamente los meses/días de las fechas de lanzamiento.\n",
    "- Contar cuantas veces aparecen en las peliculas ciertos personajes célebres.\n",
    "- Indicar si la pelicula es de una productora famosa o no.\n",
    "- Agrupar distintas keywords en categorías más generales.\n",
    "- Generar ratios con las variables numericas del dataset (como duración de la película/presupuesto).\n",
    "- Contar los diferentes generos similares que posee una pelicula.\n",
    "- Extraer vectores desde los overviews de las peliculas.\n",
    "- Contar el número de actores/productoras/géneros.\n",
    "- Etc... Usen su creatividad!\n",
    "\n",
    "Nuevamente, recuerde no utilizar ni los targets ni las labels para generar nuevas features.\n",
    "\n",
    "Nota: Este último paso no es requisito pero puede catapultarlos a la cima del tablero de las competencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26cc8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c6cd3f6",
   "metadata": {
    "cell_id": "00016-5586ef61-95ea-4f5a-8ad0-796be8c78ac0",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166471,
    "scrolled": true,
    "source_hash": "2dc8e0f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer(func=<function feature_extractor at 0x000001747FF2A040>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_extractor(X):\n",
    "    movies = X.copy()\n",
    "    movies[\"release_date_timestamp\"] = movies['release_date'].apply(lambda x: x.timestamp())\n",
    "    movies[\"release_date_month\"] = movies['release_date'].dt.month\n",
    "    movies[\"release_date_day\"] = movies['release_date'].dt.day\n",
    "    \n",
    "    top_companies = ['Warner Bros. Pictures', 'Universal Pictures', 'Columbia Pictures',\n",
    "       'Paramount', '20th Century Fox', 'Canal+', 'New Line Cinema',\n",
    "       'Metro-Goldwyn-Mayer', 'Lionsgate', 'Relativity Media',\n",
    "       'StudioCanal', 'Touchstone Pictures', 'Walt Disney Pictures',\n",
    "       'DreamWorks Pictures', 'Miramax']\n",
    "    \n",
    "    movies[\"num_top_production_companies\"] = movies[\"production_companies\"].apply(\n",
    "        lambda x: \n",
    "        sum(\n",
    "            [int(comp in str(x)) for comp in top_companies]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    top_artists = ['Samuel L. Jackson', 'Frank Welker', 'Nicolas Cage',\n",
    "       'Bruce Willis', 'Robert De Niro', 'Matt Damon', 'Liam Neeson',\n",
    "       'Willem Dafoe', 'Morgan Freeman', 'J.K. Simmons', 'Steve Buscemi',\n",
    "       'Johnny Depp', 'John Goodman', 'Paul Giamatti', 'Stanley Tucci',\n",
    "       'Woody Harrelson', 'Brad Pitt', 'Mickie McGowan', 'John Leguizamo',\n",
    "       'Robin Williams', 'Sylvester Stallone', 'Tom Hanks',\n",
    "       'Michael Papajohn', 'Nicole Kidman', 'Thomas Rosales Jr.',\n",
    "       'James Franco', 'Harrison Ford', 'Ben Affleck', 'Owen Wilson',\n",
    "       'Stephen Root', 'Julianne Moore', 'Ben Kingsley',\n",
    "       'Antonio Banderas', 'Anthony Hopkins', 'Alec Baldwin',\n",
    "       'Joe Chrest', 'Bill Hader', 'Richard Jenkins', 'John C. Reilly',\n",
    "       'Bill Murray', 'John Hurt', 'Elizabeth Banks', 'Michael Caine',\n",
    "       'Ewan McGregor', 'Keith David', 'Susan Sarandon',\n",
    "       'Fred Tatasciore', 'Bob Bergen', 'Scarlett Johansson',\n",
    "       'Keanu Reeves']\n",
    "    movies[\"num_top_artists\"] = movies[\"credits\"].apply(\n",
    "        lambda x: \n",
    "        sum(\n",
    "            [int(art in str(x).replace(\"-\", \" \")) for art in top_artists]\n",
    "        )\n",
    "    )\n",
    "    movies[\"ratio(runtime, budget)\"] = (movies[\"runtime\"]/(1+movies[\"budget\"]))\n",
    "    # Contar el número de actores/productoras/géneros.\n",
    "    movies[\"num_artists\"] = movies[\"credits\"].apply(\n",
    "        lambda x:\n",
    "        sum(\n",
    "            [len(str(x).split(\"-\"))]\n",
    "        )\n",
    "    )\n",
    "    movies[\"num_genres\"] = movies[\"genres\"].apply(\n",
    "        lambda x: len(str(x).split(\"-\"))\n",
    "    )\n",
    "    movies[\"num_production_companies\"] = movies[\"production_companies\"].apply(\n",
    "        lambda x: len(str(x).split(\"-\"))\n",
    "    )\n",
    "    movies[\"prop(num_top_production_companies)\"] = movies[\"num_top_production_companies\"]/(1+movies[\"num_production_companies\"])\n",
    "    movies[\"prop(num_top_artists)\"] = movies[\"num_top_artists\"]/(1+movies[\"num_artists\"])\n",
    "    return movies\n",
    "\n",
    "feature_tranformer = FunctionTransformer(feature_extractor)\n",
    "feature_tranformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89427e68",
   "metadata": {
    "cell_id": "ec9c0f8a2b044f858858ef3c3248c239",
    "deepnote_cell_height": 102,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "source": [
    "```\n",
    "Comentarios\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869eda7",
   "metadata": {
    "cell_id": "00018-d6de5b4a-3ce2-4aaa-9421-121c4fcaf3b5",
    "deepnote_cell_height": 117.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Clasificación\n",
    "\n",
    "### 4.1 Dummy y Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65949e",
   "metadata": {},
   "source": [
    "*En esta sección crearán el modelo más básico posible que resuelva el problema. La idea de este modelo usarlo como comparación para que en el siguiente paso lo puedan mejorar.*\n",
    "\n",
    "- Generar un modelo Dummy con estrategia estratificada que les permita comparar más adelante si su baseline de clasificación es mejor que el azar.\n",
    "- Generar un pipeline para la clasificación con un clasificador relativamente sencillo a la salida (a su elección, recomendado: arbol de decisión).\n",
    "- Evaluar ambos modelos según las métricas de evaluación y reportar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f1948d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ef6e328",
   "metadata": {
    "cell_id": "00020-830185e8-7ee6-44a5-89f0-ccb5e5d4ef76",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166499,
    "source_hash": "3e943dc6"
   },
   "outputs": [],
   "source": [
    "## Código Dummy\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=0)\n",
    "dummy_clf.fit(X_clf_train, y_clf_train)\n",
    "\n",
    "y_pred_dummy = dummy_clf.predict(X_clf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3fbe592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20a365cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67670606",
   "metadata": {
    "cell_id": "767a72b6c3ca4caa86bf94ce7f00421b",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Código Clasificador\n",
    "pipe_clf_baseline = Pipeline(\n",
    "    steps=[\n",
    "        (\"FunctionTransformer\", feature_tranformer),\n",
    "        (\"ColumnTransformer\", ct),\n",
    "        (\"clf\", RandomForestClassifier(class_weight=\"balanced\", max_depth=8, random_state=0))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d478512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.95 s\n",
      "Wall time: 6.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('FunctionTransformer',\n",
       "                 FunctionTransformer(func=<function feature_extractor at 0x000001747FF2A040>)),\n",
       "                ('ColumnTransformer',\n",
       "                 ColumnTransformer(transformers=[('OneHot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['original_language',\n",
       "                                                   'clusters_keywords',\n",
       "                                                   'clusters_overview',\n",
       "                                                   'clusters_tagline']),\n",
       "                                                 ('MinMax', MinMaxScaler(),\n",
       "                                                  ['budget',\n",
       "                                                   'release_date_mon...\n",
       "                                                  'credits'),\n",
       "                                                 ('OneHot_split_production_companies',\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x000001747FEFEF10>),\n",
       "                                                  'production_companies'),\n",
       "                                                 ('OneHot_split_keywords',\n",
       "                                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x000001747FEFEFA0>),\n",
       "                                                  'keywords')])),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(class_weight='balanced', max_depth=8,\n",
       "                                        random_state=0))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "pipe_clf_baseline.fit(X_clf_train, y_clf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "592f3475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.41 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_pred_baseline = pipe_clf_baseline.predict(X_clf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d0ce24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f76618d",
   "metadata": {
    "cell_id": "57e26f4f95c440a2be8794ea16cb12db",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador Dummy\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.20      0.23      0.21       252\n",
      "Mostly Positive       0.47      0.43      0.45       621\n",
      "       Negative       0.05      0.05      0.05        37\n",
      "       Positive       0.25      0.25      0.25       343\n",
      "  Very Positive       0.04      0.05      0.05        38\n",
      "\n",
      "       accuracy                           0.32      1291\n",
      "      macro avg       0.20      0.20      0.20      1291\n",
      "   weighted avg       0.33      0.32      0.33      1291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Código Comparación de métricas\n",
    "print(\n",
    "    \"Clasificador Dummy\\n\"+classification_report(y_clf_test, y_pred_dummy, zero_division=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d35939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador baseline: RF\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.31      0.69      0.43       252\n",
      "Mostly Positive       0.56      0.18      0.27       621\n",
      "       Negative       0.17      0.03      0.05        37\n",
      "       Positive       0.44      0.66      0.53       343\n",
      "  Very Positive       0.29      0.11      0.15        38\n",
      "\n",
      "       accuracy                           0.40      1291\n",
      "      macro avg       0.35      0.33      0.28      1291\n",
      "   weighted avg       0.46      0.40      0.36      1291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Clasificador baseline: RF\\n\"+classification_report(y_clf_test, y_pred_baseline, zero_division=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1d3a8",
   "metadata": {
    "cell_id": "8b46d8fd6f9544b199b67020abad2562",
    "deepnote_cell_height": 69.93333435058594,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "```\n",
    "Justificación\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8e074",
   "metadata": {
    "cell_id": "00021-c294ef41-853d-4297-b051-d5d4e6577715",
    "deepnote_cell_height": 61.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "### 4.2 Búsqueda del mejor modelo de Clasificación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41b3d0",
   "metadata": {},
   "source": [
    "*Aquí deberán mejorar del modelo de clasificación al variar los algoritmos/hiperparámetros que están ocupando.*\n",
    "\n",
    "- Generar una nueva `Pipeline` enfocada en buscar el mejor modelo usando GridSearch.\n",
    "- Usar **`GridSearchCV`** o **`HalvingGridSearchCV`** para tunear hiperparámetros. La primera demorará más que la segunda pero les traerá potencialmente mejores resultados. Pueden probar también [`OptunaSearchCV`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.OptunaSearchCV.html) de la librería [`Optuna`](https://optuna.org/) , la cuál es bastante popular para buscar modelos de redes neuronales.\n",
    "- Agregar técnicas de seleccion de atributos, como también usar mejores clasificadores y explorar sus hiperparámetros. \n",
    "- Probar distintos parámetros para las transformaciones de datos, seleccion de atributos, clasificadores, etc...\n",
    "- Probar modelos basados en gradient boosting/bagging. **Recomendación fuerte:** Probar [`LightGMB`](https://lightgbm.readthedocs.io/en/latest/) o [`xgboost`](https://xgboost.readthedocs.io/en/stable/).\n",
    "- Probar activando/descativando los procesadores de texto, de categorías, etc...\n",
    "- Recuerden setear la búsqueda para optimizar la métrica que se evalua en la competencia.\n",
    "\n",
    "Algunas notas interesantes sobre este proceso: \n",
    "\n",
    "- No se les pide rendimientos cercanos al 100% de la métrica para concretar exitosamente el proyecto. Por otra parte, celebren cada progreso que obtengan.\n",
    "- Hagan grillas computables: Si la grilla se va a demorar 1/3 la edad del universo en explorarse completamente, entonces achíquenla a algo que sepan que va a terminar. \n",
    "- Aprovechen el procesamiento paralelo (con `njobs`) para acelerar la búsqueda. Sin embargo, si tienen problemas con la memoria RAM, reduzca la cantidad de jobs a algo que su computador/interprete web pueda procesar.\n",
    "\n",
    "**Al final de este proceso, seleccione el mejor modelo de clasificación encontrado, prediga las labels del test set de la competencia y envíelos a Codalab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68de7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c584952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipe_model(model_class, params, params_selector, columntrans=ct):\n",
    "    model = model_class(**params)\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"FunctionTransformer\", feature_tranformer),\n",
    "            (\"ColumnTransformer\", columntrans),\n",
    "            (\"selector\", SelectPercentile(f_classif, **params_selector)),\n",
    "            ('clf', model)\n",
    "        ]\n",
    "     )\n",
    "    pipe.fit(X_clf_train, y_clf_train)\n",
    "    y_pred = pipe.predict(X_clf_test)\n",
    "    print(\n",
    "    f\"Clasificador: {model_class.__name__}\\n\"+classification_report(y_clf_test, y_pred, zero_division=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21a860f7-c51f-4c53-ab39-c8ff79fdcf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ca9d092-7355-4fd2-9a0f-6d92ac39726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: LogisticRegression\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.44      0.33      0.38       252\n",
      "Mostly Positive       0.55      0.69      0.61       621\n",
      "       Negative       1.00      0.00      0.00        37\n",
      "       Positive       0.55      0.53      0.54       343\n",
      "  Very Positive       0.00      0.00      0.00        38\n",
      "\n",
      "       accuracy                           0.54      1291\n",
      "      macro avg       0.51      0.31      0.31      1291\n",
      "   weighted avg       0.53      0.54      0.51      1291\n",
      "\n",
      "CPU times: total: 6.11 s\n",
      "Wall time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_model(\n",
    "    LogisticRegression, \n",
    "    params={\n",
    "        'max_iter': 1000,\n",
    "        'solver' : 'saga',\n",
    "        'penalty': 'l2'\n",
    "    }, \n",
    "    params_selector={\"percentile\": 95},\n",
    "    columntrans=ct_wo_bow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ef887207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: RidgeClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.35      0.32      0.33       252\n",
      "Mostly Positive       0.54      0.62      0.57       621\n",
      "       Negative       0.50      0.03      0.05        37\n",
      "       Positive       0.51      0.52      0.51       343\n",
      "  Very Positive       0.00      0.00      0.00        38\n",
      "\n",
      "       accuracy                           0.50      1291\n",
      "      macro avg       0.38      0.30      0.29      1291\n",
      "   weighted avg       0.48      0.50      0.48      1291\n",
      "\n",
      "CPU times: total: 4.69 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_model(\n",
    "    RidgeClassifier, \n",
    "    params={\n",
    "        'alpha': 0.5\n",
    "    }, \n",
    "    params_selector={\"percentile\": 95},\n",
    "    columntrans=ct_wo_bow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9fd9b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: SGDClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.42      0.26      0.32       252\n",
      "Mostly Positive       0.54      0.67      0.60       621\n",
      "       Negative       0.20      0.03      0.05        37\n",
      "       Positive       0.51      0.54      0.52       343\n",
      "  Very Positive       0.33      0.03      0.05        38\n",
      "\n",
      "       accuracy                           0.52      1291\n",
      "      macro avg       0.40      0.30      0.31      1291\n",
      "   weighted avg       0.50      0.52      0.49      1291\n",
      "\n",
      "CPU times: total: 2.34 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_model(\n",
    "    SGDClassifier, \n",
    "    params={\n",
    "        'l1_ratio': 0.7\n",
    "    }, \n",
    "    params_selector={\"percentile\": 95},\n",
    "    columntrans=ct_wo_bow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ebead9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: GradientBoostingClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.45      0.22      0.29       252\n",
      "Mostly Positive       0.57      0.77      0.66       621\n",
      "       Negative       0.12      0.03      0.04        37\n",
      "       Positive       0.61      0.56      0.58       343\n",
      "  Very Positive       0.40      0.05      0.09        38\n",
      "\n",
      "       accuracy                           0.56      1291\n",
      "      macro avg       0.43      0.33      0.33      1291\n",
      "   weighted avg       0.54      0.56      0.53      1291\n",
      "\n",
      "CPU times: total: 1min 49s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_model(\n",
    "    GradientBoostingClassifier,\n",
    "    params={  \n",
    "        'n_estimators': 300\n",
    "    }, \n",
    "    params_selector={\"percentile\": 100},\n",
    "    columntrans=ct_wo_bow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5c9467e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: BaggingClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.45      0.31      0.37       252\n",
      "Mostly Positive       0.57      0.76      0.65       621\n",
      "       Negative       1.00      0.00      0.00        37\n",
      "       Positive       0.60      0.49      0.54       343\n",
      "  Very Positive       1.00      0.00      0.00        38\n",
      "\n",
      "       accuracy                           0.56      1291\n",
      "      macro avg       0.72      0.31      0.31      1291\n",
      "   weighted avg       0.58      0.56      0.53      1291\n",
      "\n",
      "CPU times: total: 6.41 s\n",
      "Wall time: 6.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_model(\n",
    "    BaggingClassifier, \n",
    "    params={ \n",
    "        #'base_estimator': SGDClassifier(l1_ratio=0.8),\n",
    "        #'base_estimator': LogisticRegression(max_iter=1000),\n",
    "        'base_estimator': DecisionTreeClassifier(max_depth=10),\n",
    "        'n_estimators': 10\n",
    "    }, \n",
    "    params_selector={\"percentile\": 100},\n",
    "    columntrans=ct_wo_bow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "19b1bc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: RandomForestClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.32      0.67      0.44       252\n",
      "Mostly Positive       0.53      0.17      0.26       621\n",
      "       Negative       1.00      0.00      0.00        37\n",
      "       Positive       0.44      0.73      0.55       343\n",
      "  Very Positive       0.43      0.08      0.13        38\n",
      "\n",
      "       accuracy                           0.41      1291\n",
      "      macro avg       0.54      0.33      0.28      1291\n",
      "   weighted avg       0.48      0.41      0.36      1291\n",
      "\n",
      "CPU times: total: 9.25 s\n",
      "Wall time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_model(\n",
    "    RandomForestClassifier, \n",
    "    params={\"class_weight\": \"balanced\", \"max_depth\": 15, \"n_estimators\": 150, \"random_state\": 0}, \n",
    "    params_selector={\"percentile\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03f8ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: DecisionTreeClassifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.36      0.25      0.30       252\n",
      "Mostly Positive       0.52      0.67      0.59       621\n",
      "       Negative       0.33      0.03      0.05        37\n",
      "       Positive       0.48      0.41      0.44       343\n",
      "  Very Positive       0.23      0.13      0.17        38\n",
      "\n",
      "       accuracy                           0.48      1291\n",
      "      macro avg       0.39      0.30      0.31      1291\n",
      "   weighted avg       0.47      0.48      0.46      1291\n",
      "\n",
      "CPU times: total: 8.84 s\n",
      "Wall time: 8.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_model(\n",
    "    DecisionTreeClassifier, \n",
    "    params={\"class_weight\": None, \"max_depth\": 15, \"random_state\": 0}, \n",
    "    params_selector={\"percentile\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cc662277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"FunctionTransformer\", feature_tranformer),\n",
    "            (\"ColumnTransformer\", ct),\n",
    "            (\"selector\", SelectPercentile(f_classif, percentile=50)),\n",
    "            ('clf', LinearSVC())\n",
    "        ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "94052ed8",
   "metadata": {
    "cell_id": "00022-b323dc3e-6fa0-4d50-8a50-56ad708178ba",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166499,
    "source_hash": "8f673430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código GridSearch\n",
    "param_grid = [\n",
    "    # grilla 1: LogisticRegression\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"clf\": [LogisticRegression(random_state=42)],\n",
    "        \"clf__C\": [0.5, 1, 1.5],\n",
    "        \"clf__max_iter\": [900, 1000, 1100],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 2: GradientBoostingClassifier\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"clf\": [GradientBoostingClassifier(random_state=42)],\n",
    "        \"clf__n_estimators\": [150, 200, 250],\n",
    "        \"clf__learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "    # grilla 3: BaggingClassifier\n",
    "    {\n",
    "        \"selector__percentile\": [25, 50, 75, 95, 100],\n",
    "        \"clf\": [BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=10),random_state=42)],\n",
    "        \"clf__n_estimators\": [25, 50, 75],\n",
    "        \"ColumnTransformer\": [ct, ct_wo_bow]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "09850ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "31fd5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid, n_jobs=-1, scoring='f1_macro', verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4bc96b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 210 candidates, totalling 1050 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [141]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_clf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_clf_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\.conda\\envs\\mds7202\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gs.fit(X_clf_train, y_clf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "691fe7c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_score_\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "0f6ce28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('FunctionTransformer',\n",
       "   FunctionTransformer(func=<function feature_extractor at 0x00000234FB76D160>)),\n",
       "  ('ColumnTransformer',\n",
       "   ColumnTransformer(transformers=[('OneHot',\n",
       "                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                    ['original_language', 'clusters_keywords',\n",
       "                                     'clusters_overview', 'clusters_tagline']),\n",
       "                                   ('MinMax', MinMaxScaler(),\n",
       "                                    ['budget', 'release_date_month',\n",
       "                                     'release_date_day',\n",
       "                                     'num_top_production_companies',\n",
       "                                     'num_top_artists', 'ratio(runtime, budget)',\n",
       "                                     'num_artists', 'num_genres',\n",
       "                                     'num_product...\n",
       "                                   ('OneHot_split_credits',\n",
       "                                    CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000234940BA670>),\n",
       "                                    'credits'),\n",
       "                                   ('OneHot_split_production_companies',\n",
       "                                    CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360BE0>),\n",
       "                                    'production_companies'),\n",
       "                                   ('OneHot_split_keywords',\n",
       "                                    CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360040>),\n",
       "                                    'keywords')])),\n",
       "  ('selector', SelectPercentile(percentile=95)),\n",
       "  ('clf', LinearSVC(C=0.001, class_weight='balanced', random_state=42))],\n",
       " 'verbose': False,\n",
       " 'FunctionTransformer': FunctionTransformer(func=<function feature_extractor at 0x00000234FB76D160>),\n",
       " 'ColumnTransformer': ColumnTransformer(transformers=[('OneHot',\n",
       "                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                  ['original_language', 'clusters_keywords',\n",
       "                                   'clusters_overview', 'clusters_tagline']),\n",
       "                                 ('MinMax', MinMaxScaler(),\n",
       "                                  ['budget', 'release_date_month',\n",
       "                                   'release_date_day',\n",
       "                                   'num_top_production_companies',\n",
       "                                   'num_top_artists', 'ratio(runtime, budget)',\n",
       "                                   'num_artists', 'num_genres',\n",
       "                                   'num_product...\n",
       "                                 ('OneHot_split_credits',\n",
       "                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000234940BA670>),\n",
       "                                  'credits'),\n",
       "                                 ('OneHot_split_production_companies',\n",
       "                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360BE0>),\n",
       "                                  'production_companies'),\n",
       "                                 ('OneHot_split_keywords',\n",
       "                                  CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360040>),\n",
       "                                  'keywords')]),\n",
       " 'selector': SelectPercentile(percentile=95),\n",
       " 'clf': LinearSVC(C=0.001, class_weight='balanced', random_state=42),\n",
       " 'FunctionTransformer__accept_sparse': False,\n",
       " 'FunctionTransformer__check_inverse': True,\n",
       " 'FunctionTransformer__func': <function __main__.feature_extractor(X)>,\n",
       " 'FunctionTransformer__inv_kw_args': None,\n",
       " 'FunctionTransformer__inverse_func': None,\n",
       " 'FunctionTransformer__kw_args': None,\n",
       " 'FunctionTransformer__validate': False,\n",
       " 'ColumnTransformer__n_jobs': None,\n",
       " 'ColumnTransformer__remainder': 'drop',\n",
       " 'ColumnTransformer__sparse_threshold': 0.3,\n",
       " 'ColumnTransformer__transformer_weights': None,\n",
       " 'ColumnTransformer__transformers': [('OneHot',\n",
       "   OneHotEncoder(handle_unknown='ignore'),\n",
       "   ['original_language',\n",
       "    'clusters_keywords',\n",
       "    'clusters_overview',\n",
       "    'clusters_tagline']),\n",
       "  ('MinMax',\n",
       "   MinMaxScaler(),\n",
       "   ['budget',\n",
       "    'release_date_month',\n",
       "    'release_date_day',\n",
       "    'num_top_production_companies',\n",
       "    'num_top_artists',\n",
       "    'ratio(runtime, budget)',\n",
       "    'num_artists',\n",
       "    'num_genres',\n",
       "    'num_production_companies',\n",
       "    'prop(num_top_production_companies)',\n",
       "    'prop(num_top_artists)']),\n",
       "  ('Standard', StandardScaler(), ['runtime', 'release_date_timestamp']),\n",
       "  ('OneHot_split_genres',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000234940BAA60>),\n",
       "   'genres'),\n",
       "  ('OneHot_split_credits',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000234940BA670>),\n",
       "   'credits'),\n",
       "  ('OneHot_split_production_companies',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360BE0>),\n",
       "   'production_companies'),\n",
       "  ('OneHot_split_keywords',\n",
       "   CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360040>),\n",
       "   'keywords')],\n",
       " 'ColumnTransformer__verbose': False,\n",
       " 'ColumnTransformer__verbose_feature_names_out': True,\n",
       " 'ColumnTransformer__OneHot': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'ColumnTransformer__MinMax': MinMaxScaler(),\n",
       " 'ColumnTransformer__Standard': StandardScaler(),\n",
       " 'ColumnTransformer__OneHot_split_genres': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000234940BAA60>),\n",
       " 'ColumnTransformer__OneHot_split_credits': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x00000234940BA670>),\n",
       " 'ColumnTransformer__OneHot_split_production_companies': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360BE0>),\n",
       " 'ColumnTransformer__OneHot_split_keywords': CountVectorizer(tokenizer=<__main__.SplitTokenizer object at 0x0000023494360040>),\n",
       " 'ColumnTransformer__OneHot__categories': 'auto',\n",
       " 'ColumnTransformer__OneHot__drop': None,\n",
       " 'ColumnTransformer__OneHot__dtype': numpy.float64,\n",
       " 'ColumnTransformer__OneHot__handle_unknown': 'ignore',\n",
       " 'ColumnTransformer__OneHot__sparse': True,\n",
       " 'ColumnTransformer__MinMax__clip': False,\n",
       " 'ColumnTransformer__MinMax__copy': True,\n",
       " 'ColumnTransformer__MinMax__feature_range': (0, 1),\n",
       " 'ColumnTransformer__Standard__copy': True,\n",
       " 'ColumnTransformer__Standard__with_mean': True,\n",
       " 'ColumnTransformer__Standard__with_std': True,\n",
       " 'ColumnTransformer__OneHot_split_genres__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_genres__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_genres__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_genres__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_genres__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_genres__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_genres__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_genres__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_genres__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_genres__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_genres__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_genres__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_genres__tokenizer': <__main__.SplitTokenizer at 0x234940baa60>,\n",
       " 'ColumnTransformer__OneHot_split_genres__vocabulary': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_credits__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_credits__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_credits__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_credits__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_credits__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_credits__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_credits__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_credits__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_credits__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_credits__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_credits__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_credits__tokenizer': <__main__.SplitTokenizer at 0x234940ba670>,\n",
       " 'ColumnTransformer__OneHot_split_credits__vocabulary': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_production_companies__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_production_companies__tokenizer': <__main__.SplitTokenizer at 0x23494360be0>,\n",
       " 'ColumnTransformer__OneHot_split_production_companies__vocabulary': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__analyzer': 'word',\n",
       " 'ColumnTransformer__OneHot_split_keywords__binary': False,\n",
       " 'ColumnTransformer__OneHot_split_keywords__decode_error': 'strict',\n",
       " 'ColumnTransformer__OneHot_split_keywords__dtype': numpy.int64,\n",
       " 'ColumnTransformer__OneHot_split_keywords__encoding': 'utf-8',\n",
       " 'ColumnTransformer__OneHot_split_keywords__input': 'content',\n",
       " 'ColumnTransformer__OneHot_split_keywords__lowercase': True,\n",
       " 'ColumnTransformer__OneHot_split_keywords__max_df': 1.0,\n",
       " 'ColumnTransformer__OneHot_split_keywords__max_features': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__min_df': 1,\n",
       " 'ColumnTransformer__OneHot_split_keywords__ngram_range': (1, 1),\n",
       " 'ColumnTransformer__OneHot_split_keywords__preprocessor': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__stop_words': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__strip_accents': None,\n",
       " 'ColumnTransformer__OneHot_split_keywords__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'ColumnTransformer__OneHot_split_keywords__tokenizer': <__main__.SplitTokenizer at 0x23494360040>,\n",
       " 'ColumnTransformer__OneHot_split_keywords__vocabulary': None,\n",
       " 'selector__percentile': 95,\n",
       " 'selector__score_func': <function sklearn.feature_selection._univariate_selection.f_classif(X, y)>,\n",
       " 'clf__C': 0.001,\n",
       " 'clf__class_weight': 'balanced',\n",
       " 'clf__dual': True,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__intercept_scaling': 1,\n",
       " 'clf__loss': 'squared_hinge',\n",
       " 'clf__max_iter': 1000,\n",
       " 'clf__multi_class': 'ovr',\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__random_state': 42,\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__verbose': 0}"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipe = gs.best_estimator_\n",
    "best_pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "0078f083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador: best_pipe\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mixed       0.42      0.42      0.42       252\n",
      "Mostly Positive       0.59      0.56      0.57       621\n",
      "       Negative       0.23      0.14      0.17        37\n",
      "       Positive       0.53      0.65      0.58       343\n",
      "  Very Positive       0.11      0.03      0.04        38\n",
      "\n",
      "       accuracy                           0.53      1291\n",
      "      macro avg       0.37      0.36      0.36      1291\n",
      "   weighted avg       0.52      0.53      0.52      1291\n",
      "\n",
      "CPU times: total: 1.16 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = best_pipe\n",
    "pipe.fit(X_clf_train, y_clf_train)\n",
    "y_pred = pipe.predict(X_clf_test)\n",
    "print(\n",
    "    f\"Clasificador: best_pipe\\n\"+classification_report(y_clf_test, y_pred, zero_division=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa03c6",
   "metadata": {
    "cell_id": "12d71cdc88dd4c06b9a7e1696853f7b2",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código Predicción de datos de la competencia aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7454a",
   "metadata": {
    "cell_id": "00023-73786884-e1b2-448a-9636-ab05cf3c1fc5",
    "deepnote_cell_height": 69.93333435058594,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "```\n",
    "Justificación Aquí\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce5d7d1",
   "metadata": {
    "cell_id": "00025-2acf9c12-da85-4c1f-add5-f2b0f600177f",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Conclusiones Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996db4c2",
   "metadata": {
    "cell_id": "00026-15c07b20-0e16-48fa-bf3c-33aeb2c4c1db",
    "deepnote_cell_height": 51.53334045410156,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Conclusiones...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18bac5d",
   "metadata": {
    "cell_id": "00027-1e362e1d-a776-4423-93d5-0f568476e4c1",
    "deepnote_cell_height": 84.10000610351562,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Anexo: Generación de Archivo Submit de la Competencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f6447",
   "metadata": {
    "cell_id": "00028-0a64e7e8-1077-4868-8c96-db3d51323157",
    "deepnote_cell_height": 671.9000244140625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Para subir los resultados obtenidos a la pagina de CodaLab utilice la función `generateFiles` entregada mas abajo. Esto es debido a que usted deberá generar archivos que respeten extrictamente el formato de CodaLab, de lo contario los resultados no se veran reflejados en la pagina de la competencia.\n",
    "\n",
    "Para los resultados obtenidos en su modelo de clasificación y regresión, estos serán guardados en un archivo zip que contenga los archivos `predicctions_clf.txt` para la clasificación y `predicctions_rgr.clf` para la regresión. Los resultados, como se comento antes, deberan ser obtenidos en base al dataset `test.pickle` y en cada una de las lineas deberan presentar las predicciones realizadas.\n",
    "\n",
    "Ejemplos de archivos:\n",
    "\n",
    "- [ ] `predicctions_clf.txt`\n",
    "\n",
    "        Mostly Positive\n",
    "        Mostly Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        ...\n",
    "\n",
    "- [ ] `predicctions_rgr.txt`\n",
    "\n",
    "        16103.58\n",
    "        16103.58\n",
    "        16041.89\n",
    "        9328.62\n",
    "        107976.03\n",
    "        194374.08\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f33d5d",
   "metadata": {
    "cell_id": "00029-55f95a4c-2d1f-4354-a690-049fea34bdac",
    "deepnote_cell_height": 620.13330078125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166501,
    "source_hash": "b1cdf32f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "def generateFiles(predict_data, clf_pipe, rgr_pipe):\n",
    "    \"\"\"Genera los archivos a subir en CodaLab\n",
    "\n",
    "    Input\n",
    "    predict_data: Dataframe con los datos de entrada a predecir\n",
    "    clf_pipe: pipeline del clf\n",
    "    rgr_pipe: pipeline del rgr\n",
    "\n",
    "    Ouput\n",
    "    archivo de txt\n",
    "    \"\"\"\n",
    "    y_pred_clf = clf_pipe.predict(predict_data)\n",
    "    y_pred_rgr = rgr_pipe.predict(predict_data)\n",
    "    \n",
    "    with open('./predictions_clf.txt', 'w') as f:\n",
    "        for item in y_pred_clf:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open('./predictions_rgr.txt', 'w') as f:\n",
    "        for item in y_pred_rgr:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with ZipFile('predictions.zip', 'w') as zipObj2:\n",
    "       zipObj2.write('predictions_rgr.txt')\n",
    "       zipObj2.write('predictions_clf.txt')\n",
    "\n",
    "    os.remove(\"predictions_rgr.txt\")\n",
    "    os.remove(\"predictions_clf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1efe0",
   "metadata": {
    "cell_id": "b589f659ce2246919e3707e79420aff2",
    "deepnote_cell_height": 138,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejecutar función para generar el archivo de predicciones.\n",
    "# perdict_data debe tener cargada los datos del text.pickle\n",
    "# mientras que clf_pipe y rgr_pipe, son los pipeline de \n",
    "# clasificación y regresión respectivamente.\n",
    "generateFiles(predict_data, clf_pipe, rgr_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f8d39",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "dbddc0f3-10b8-4160-bc27-ac993196164c",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
